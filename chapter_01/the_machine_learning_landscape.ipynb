# Bab 1: The Machine Learning Landscape

---

## 1. Apa Itu Machine Learning?

Machine Learning (ML) adalah ilmu (dan seni) memprogram komputer sehingga mereka dapat belajar dari data. 

Menurut Arthur Samuel (1959), Machine Learning adalah "bidang studi yang memberikan komputer kemampuan untuk belajar tanpa diprogram secara eksplisit."  Tom Mitchell (1997) memberikan definisi yang lebih berorientasi pada rekayasa: "Sebuah program komputer dikatakan belajar dari pengalaman E terhadap suatu tugas T dan ukuran kinerja P, jika kinerjanya pada T, sebagaimana diukur oleh P, meningkat dengan pengalaman E." 

**Contoh Sederhana: Filter Spam**

Bayangkan sebuah filter spam. Tugas (T) adalah menandai email spam baru.  Pengalaman (E) adalah data pelatihan, yang terdiri dari contoh email spam (misalnya, ditandai oleh pengguna) dan email non-spam (ham).  Ukuran kinerja (P) bisa berupa rasio email yang diklasifikasikan dengan benar, yang sering disebut akurasi dalam tugas klasifikasi. 

Jika Anda hanya mengunduh salinan Wikipedia, komputer Anda memiliki lebih banyak data, tetapi ia tidak tiba-tiba menjadi lebih baik dalam tugas apa pun. Jadi, mengunduh salinan Wikipedia bukanlah Machine Learning. 

### Mengapa Menggunakan Machine Learning?

Pertimbangkan bagaimana Anda akan menulis filter spam menggunakan teknik pemrograman tradisional (seperti pada Gambar 1-1 di buku): 
1.  Anda akan mengidentifikasi pola-pola umum dalam email spam (misalnya, kata-kata seperti "4U", "kartu kredit", "gratis"). 
2.  Anda akan menulis algoritma deteksi untuk setiap pola tersebut. 
3.  Anda akan menguji program Anda dan mengulang langkah 1 dan 2 hingga cukup baik untuk diluncurkan. 

Pendekatan ini akan menghasilkan daftar aturan yang panjang dan kompleks, yang sulit dipelihara. 

Sebaliknya, filter spam berbasis Machine Learning (seperti pada Gambar 1-2 di buku) secara otomatis belajar pola-pola kata dan frasa yang menjadi prediktor spam yang baik, tanpa perlu aturan eksplisit dari Anda.  Program ini akan lebih pendek, lebih mudah dipelihara, dan kemungkinan besar lebih akurat. 

Keunggulan lain Machine Learning adalah kemampuannya untuk beradaptasi secara otomatis terhadap perubahan.  Jika pengirim spam mengubah taktik (misalnya, menulis "For U" alih-alih "4U"), filter spam tradisional perlu diperbarui secara manual.  Filter spam ML akan secara otomatis mendeteksi pola baru ini dari umpan balik pengguna dan mulai menandainya sebagai spam tanpa intervensi Anda (seperti pada Gambar 1-3 di buku). 

Machine Learning juga sangat baik untuk masalah yang terlalu kompleks untuk pendekatan tradisional atau yang tidak memiliki algoritma yang diketahui (misalnya, pengenalan suara). 

Terakhir, Machine Learning dapat membantu manusia belajar (seperti pada Gambar 1-4 di buku).  Algoritma ML dapat diperiksa untuk mengungkap pola atau tren yang tidak terduga dalam data, yang dapat mengarah pada pemahaman masalah yang lebih baik (ini disebut *data mining*). 

**Ringkasan Manfaat Machine Learning:** 
* Masalah yang memerlukan banyak penyesuaian atau daftar aturan yang panjang.
* Masalah kompleks yang tidak ada solusi bagus dengan pendekatan tradisional.
* Lingkungan yang berfluktuasi, karena sistem ML dapat beradaptasi dengan data baru.
* Mendapatkan wawasan tentang masalah kompleks dan sejumlah besar data.

---

## 2. Contoh Aplikasi Machine Learning

Machine Learning digunakan dalam berbagai aplikasi nyata: 
* **Analisis gambar produk di lini produksi untuk klasifikasi otomatis:** Klasifikasi gambar, biasanya menggunakan jaringan saraf konvolusional (CNNs). 
* **Mendeteksi tumor pada pindaian otak:** Segmentasi semantik, mengklasifikasikan setiap piksel, juga menggunakan CNNs. 
* **Mengklasifikasikan artikel berita secara otomatis:** Pemrosesan bahasa alami (NLP), khususnya klasifikasi teks, dapat ditangani dengan RNNs, CNNs, atau Transformers. 
* **Menandai komentar ofensif di forum diskusi secara otomatis:** Klasifikasi teks, menggunakan alat NLP yang sama. 
* **Meringkas dokumen panjang secara otomatis:** Ringkasan teks (NLP). 
* **Membuat chatbot atau asisten pribadi:** Melibatkan banyak komponen NLP, termasuk pemahaman bahasa alami (NLU) dan modul tanya jawab. 
* **Memperkirakan pendapatan perusahaan tahun depan:** Tugas regresi, menggunakan model regresi apa pun (misalnya, Regresi Linear, Random Forest, jaringan saraf tiruan, atau RNNs, CNNs, atau Transformers jika mempertimbangkan urutan metrik kinerja). 
* **Membuat aplikasi bereaksi terhadap perintah suara:** Pengenalan suara, menggunakan RNNs, CNNs, atau Transformers untuk memproses sampel audio. 
* **Mendeteksi penipuan kartu kredit:** Deteksi anomali. 
* **Segmentasi klien berdasarkan pembelian:** *Clustering*. 
* **Merepresentasikan kumpulan data multidimensional yang kompleks dalam diagram yang jelas:** Visualisasi data, seringkali melibatkan teknik reduksi dimensi. 
* **Merekomendasikan produk yang diminati klien:** Sistem rekomendasi, seringkali menggunakan jaringan saraf tiruan. 
* **Membangun bot cerdas untuk game:** Pembelajaran Penguatan (Reinforcement Learning/RL), di mana agen belajar strategi terbaik melalui coba-coba untuk memaksimalkan hadiah.  Contohnya adalah program AlphaGo. 

---

## 3. Jenis-Jenis Sistem Machine Learning

Sistem Machine Learning dapat diklasifikasikan berdasarkan kriteria berikut: 
* Apakah mereka dilatih dengan pengawasan manusia (Supervised, Unsupervised, Semisupervised, Reinforcement Learning).
* Apakah mereka dapat belajar secara bertahap (Online vs. Batch Learning).
* Bagaimana mereka bekerja (Instance-Based vs. Model-Based Learning).

Kriteria-kriteria ini tidak eksklusif dan dapat digabungkan. 

### 3.1. Supervised Learning / Unsupervised Learning

**Supervised Learning (Pembelajaran Terawasi)**

Dalam pembelajaran terawasi, *training set* yang Anda berikan kepada algoritma mencakup solusi yang diinginkan, yang disebut *labels*. 

* **Tugas Klasifikasi:** Filter spam adalah contoh yang baik. Sistem dilatih dengan banyak contoh email beserta kelasnya (spam atau ham), dan harus belajar cara mengklasifikasikan email baru. 
* **Tugas Regresi:** Memprediksi nilai target numerik, seperti harga mobil, berdasarkan satu set fitur (mileage, usia, merek, dll.) yang disebut *predictors*.  Untuk melatih sistem, Anda perlu memberikannya banyak contoh mobil, termasuk *predictors* dan *labels* (harga). 

Dalam Machine Learning, *attribute* adalah tipe data (misalnya, "mileage"), sementara *feature* memiliki beberapa arti tergantung konteksnya, tetapi umumnya berarti *attribute* ditambah nilainya (misalnya, "mileage = 15.000"). Banyak orang menggunakan kata *attribute* dan *feature* secara bergantian. 

Beberapa algoritma penting dalam *supervised learning* antara lain: 
* k-Nearest Neighbors
* Linear Regression
* Logistic Regression
* Support Vector Machines (SVMs)
* Decision Trees dan Random Forests
* Neural networks

**Unsupervised Learning (Pembelajaran Tanpa Pengawasan)**

Dalam pembelajaran tanpa pengawasan, data pelatihan tidak memiliki *label*.  Sistem mencoba belajar tanpa "guru". 

Beberapa algoritma penting dalam *unsupervised learning* antara lain: 
* **Clustering:** K-Means, DBSCAN, Hierarchical Cluster Analysis (HCA). Contoh: mendeteksi kelompok pengunjung blog yang mirip (seperti pada Gambar 1-8 di buku). 
* **Anomaly detection (Deteksi Anomali) dan Novelty detection (Deteksi Kebaruan):** One-class SVM, Isolation Forest. Contoh: mendeteksi transaksi kartu kredit yang tidak biasa. 
* **Visualization (Visualisasi) dan Dimensionality Reduction (Reduksi Dimensi):** Principal Component Analysis (PCA), Kernel PCA, Locally Linear Embedding (LLE), t-Distributed Stochastic Neighbor Embedding (t-SNE). Algoritma visualisasi menghasilkan representasi 2D atau 3D dari data kompleks dan tanpa label (seperti pada Gambar 1-9 di buku).  Reduksi dimensi bertujuan untuk menyederhanakan data tanpa kehilangan terlalu banyak informasi, seringkali dengan menggabungkan fitur-fitur yang berkorelasi (disebut *feature extraction*). 
* **Association Rule Learning:** Apriori, Eclat. Bertujuan menemukan hubungan menarik antara atribut dalam jumlah data besar (misalnya, orang yang membeli saus barbekyu juga membeli steak). 

**Semisupervised Learning (Pembelajaran Semi-Terawasi)**

Algoritma semisupervised learning dapat menangani data yang sebagian diberi *label*.  Ini umum karena pemberian *label* data biasanya memakan waktu dan biaya.  Sebagian besar algoritma *semisupervised learning* adalah kombinasi dari algoritma *unsupervised* dan *supervised*.  Contoh: layanan foto yang mengkluster wajah (tanpa pengawasan) dan kemudian meminta Anda untuk memberi *label* pada beberapa orang (pengawasan) untuk mengidentifikasi semua orang di semua foto (seperti pada Gambar 1-11 di buku). 

**Reinforcement Learning (Pembelajaran Penguatan)**

Pembelajaran Penguatan adalah pendekatan yang sangat berbeda. Sistem pembelajaran, yang disebut *agent*, dapat mengamati lingkungan, memilih dan melakukan tindakan, dan mendapatkan *rewards* (atau *penalties* berupa *rewards* negatif) sebagai imbalan.  *Agent* harus belajar sendiri strategi terbaik, yang disebut *policy*, untuk mendapatkan *reward* terbanyak seiring waktu.  *Policy* mendefinisikan tindakan apa yang harus dipilih *agent* dalam situasi tertentu. 

Contoh: robot yang belajar cara berjalan, atau program AlphaGo yang mengalahkan juara dunia Go (seperti pada Gambar 1-12 di buku). 

### 3.2. Batch Learning vs. Online Learning

**Batch Learning (Pembelajaran Batch)**

Dalam *batch learning*, sistem tidak dapat belajar secara bertahap.  Ia harus dilatih menggunakan semua data yang tersedia, yang biasanya memakan waktu dan sumber daya komputasi yang besar.  Pelatihan biasanya dilakukan secara *offline*.  Setelah dilatih, sistem diluncurkan ke produksi dan berjalan tanpa belajar lagi; ia hanya menerapkan apa yang telah dipelajarinya. 

Jika Anda ingin sistem *batch learning* mengetahui data baru (misalnya, jenis spam baru), Anda perlu melatih versi baru sistem dari awal menggunakan seluruh *dataset* (bukan hanya data baru, tetapi juga data lama), lalu menghentikan sistem lama dan menggantinya dengan yang baru. 

Meskipun proses ini bisa diotomatisasi (seperti pada Gambar 1-3 di buku), pelatihan menggunakan seluruh *dataset* dapat memakan waktu berjam-jam, sehingga sistem baru biasanya hanya dilatih setiap 24 jam atau mingguan.  Jika data sering berubah atau jumlah data sangat besar sehingga tidak muat di memori, *batch learning* bisa menjadi masalah. 

**Online Learning (Pembelajaran Online)**

Dalam *online learning*, Anda melatih sistem secara bertahap dengan memberinya contoh data secara berurutan, baik secara individual atau dalam kelompok kecil yang disebut *mini-batches*.  Setiap langkah pembelajaran cepat dan murah, sehingga sistem dapat belajar tentang data baru secara *real-time* saat data tiba (seperti pada Gambar 1-13 di buku). 

*Online learning* sangat baik untuk sistem yang menerima data sebagai aliran berkelanjutan (misalnya, harga saham) dan perlu beradaptasi dengan perubahan dengan cepat atau secara otonom.  Ini juga merupakan pilihan yang baik jika Anda memiliki sumber daya komputasi yang terbatas, karena sistem tidak perlu menyimpan semua data pelatihan lama setelah belajar dari data baru. 

Algoritma *online learning* juga dapat digunakan untuk melatih sistem pada *dataset* besar yang tidak muat di memori utama satu mesin (*out-of-core learning*). 

Parameter penting dalam sistem *online learning* adalah seberapa cepat mereka harus beradaptasi dengan perubahan data, yang disebut *learning rate*.  *Learning rate* yang tinggi akan membuat sistem cepat beradaptasi tetapi juga cepat melupakan data lama.  *Learning rate* yang rendah akan membuat sistem lebih lambat belajar tetapi kurang sensitif terhadap *noise* atau *outliers*. 

Tantangan besar dengan *online learning* adalah jika data buruk dimasukkan ke dalam sistem, kinerja sistem akan menurun secara bertahap.  Untuk mengurangi risiko ini, Anda perlu memantau sistem dengan cermat dan segera mematikan pembelajaran jika mendeteksi penurunan kinerja. 

### 3.3. Instance-Based Learning vs. Model-Based Learning

**Instance-Based Learning (Pembelajaran Berbasis Instans)**

Pembelajaran berbasis instans adalah bentuk pembelajaran paling sederhana di mana sistem hanya mempelajari contoh-contohnya.  Ketika menerima kasus baru, ia menggunakan ukuran kemiripan untuk membandingkannya dengan contoh-contoh yang telah dipelajari dan membuat prediksi. 

Contoh: Filter spam yang menandai email yang sangat mirip dengan email spam yang sudah diketahui.  Email baru akan diklasifikasikan sebagai spam jika memiliki banyak kata yang sama dengan email spam yang diketahui. 

**Model-Based Learning (Pembelajaran Berbasis Model)**

Pendekatan lain untuk menggeneralisasi dari serangkaian contoh adalah dengan membangun sebuah model dari contoh-contoh tersebut dan kemudian menggunakan model tersebut untuk membuat prediksi. 

Contoh: Memprediksi kepuasan hidup berdasarkan PDB per kapita.  Anda dapat memodelkan kepuasan hidup sebagai fungsi linear dari PDB per kapita (Persamaan 1-1 di buku).  Model ini memiliki dua parameter, $\theta_0$ dan $\theta_1$. 

**Langkah-langkah umum dalam Model-Based Learning:** 
1.  Mempelajari data. 
2.  Memilih model (misalnya, model linear). 
3.  Melatih model pada data pelatihan (yaitu, algoritma pembelajaran mencari nilai parameter model yang meminimalkan fungsi biaya). 
4.  Menerapkan model untuk membuat prediksi pada kasus-kasus baru (*inference*), dengan harapan model ini akan menggeneralisasi dengan baik. 

---

## 4. Tantangan Utama Machine Learning

Dalam Machine Learning, dua hal utama yang bisa salah adalah "algoritma buruk" dan "data buruk". 

### 4.1. Kuantitas Data Pelatihan yang Tidak Cukup

Sebagian besar algoritma Machine Learning membutuhkan banyak data untuk berfungsi dengan baik.  Bahkan untuk masalah yang sangat sederhana, Anda biasanya memerlukan ribuan contoh, dan untuk masalah kompleks (misalnya, pengenalan gambar atau suara), Anda mungkin memerlukan jutaan contoh. 

Penelitian menunjukkan bahwa dengan data yang cukup, algoritma Machine Learning yang sangat berbeda, termasuk yang relatif sederhana, menunjukkan kinerja yang hampir sama baiknya pada masalah kompleks. 

### 4.2. Data Pelatihan yang Tidak Representatif

Agar dapat menggeneralisasi dengan baik, sangat penting bahwa data pelatihan Anda representatif terhadap kasus-kasus baru yang ingin Anda generalisasi.  Hal ini berlaku baik Anda menggunakan *instance-based learning* maupun *model-based learning*. 

Jika sampel terlalu kecil, Anda akan memiliki *sampling noise* (data non-representatif karena kebetulan).  Bahkan sampel yang sangat besar bisa jadi non-representatif jika metode pengambilan sampelnya cacat (disebut *sampling bias*). 

### 4.3. Data Berkualitas Buruk

Jika data pelatihan Anda penuh dengan kesalahan, *outliers*, dan *noise* (misalnya, karena pengukuran yang buruk), akan lebih sulit bagi sistem untuk mendeteksi pola yang mendasarinya, sehingga sistem Anda cenderung tidak berkinerja baik.  Seringkali, membersihkan data pelatihan sangatlah berharga. 

### 4.4. Fitur yang Tidak Relevan

Sistem Anda hanya akan mampu belajar jika data pelatihan mengandung fitur yang cukup relevan dan tidak terlalu banyak fitur yang tidak relevan.  Bagian penting dari keberhasilan proyek Machine Learning adalah menemukan kumpulan fitur yang baik untuk dilatih. Proses ini, disebut *feature engineering*, melibatkan langkah-langkah: 
* *Feature selection* (memilih fitur yang paling berguna dari yang sudah ada). 
* *Feature extraction* (menggabungkan fitur yang sudah ada untuk menghasilkan fitur yang lebih berguna; algoritma reduksi dimensi dapat membantu). 
* Membuat fitur baru dengan mengumpulkan data baru. 

### 4.5. Overfitting Data Pelatihan

*Overfitting* terjadi ketika model berkinerja baik pada data pelatihan, tetapi tidak menggeneralisasi dengan baik pada kasus-kasus baru.  Model yang kompleks (misalnya, jaringan saraf dalam) dapat mendeteksi pola halus dalam data.  Namun, jika *training set* berisik atau terlalu kecil, model cenderung mendeteksi pola dalam *noise* itu sendiri, yang tidak akan menggeneralisasi pada instans baru. 

**Solusi untuk *Overfitting*:** 
* Sederhanakan model (misalnya, model linear daripada model polinomial derajat tinggi), kurangi jumlah atribut dalam data pelatihan, atau batasi model (*regularization*). 
* Kumpulkan lebih banyak data pelatihan. 
* Kurangi *noise* dalam data pelatihan (misalnya, perbaiki kesalahan data dan hapus *outliers*). 

*Regularization* adalah tindakan membatasi model agar lebih sederhana dan mengurangi risiko *overfitting*.  Tingkat *regularization* dikontrol oleh *hyperparameter*. 

### 4.6. Underfitting Data Pelatihan

*Underfitting* adalah kebalikan dari *overfitting*: terjadi ketika model Anda terlalu sederhana untuk mempelajari struktur dasar data.  Model semacam itu akan menghasilkan prediksi yang tidak akurat, bahkan pada contoh pelatihan. 

**Solusi untuk *Underfitting*:** 
* Pilih model yang lebih kuat, dengan lebih banyak parameter. 
* Berikan fitur yang lebih baik ke algoritma pembelajaran (*feature engineering*). 
* Kurangi batasan pada model (misalnya, kurangi *hyperparameter regularization*). 

---

## 5. Pengujian dan Validasi

Satu-satunya cara untuk mengetahui seberapa baik model akan menggeneralisasi pada kasus-kasus baru adalah dengan benar-benar mengujinya pada kasus-kasus baru. 

### 5.1. Test Set

Pisahkan data Anda menjadi dua set: *training set* dan *test set*.  Anda melatih model menggunakan *training set*, dan mengujinya menggunakan *test set*.  Tingkat kesalahan pada kasus-kasus baru disebut *generalization error* (atau *out-of-sample error*), dan dengan mengevaluasi model pada *test set*, Anda mendapatkan estimasi dari kesalahan ini. 

Jika kesalahan pelatihan rendah tetapi kesalahan generalisasi tinggi, berarti model Anda *overfitting* data pelatihan.  Umumnya, 80% data digunakan untuk pelatihan dan 20% untuk pengujian, tetapi ini tergantung pada ukuran *dataset*. 

**Penting:** Jangan pernah melihat *test set* sampai Anda siap untuk meluncurkan model. Jika Anda melihat *test set*, Anda berisiko memperkenalkan *data snooping bias*, yang dapat menyebabkan estimasi kesalahan generalisasi menjadi terlalu optimis. 

### 5.2. Hyperparameter Tuning dan Model Selection

Untuk memilih model dan menyetel *hyperparameter*, Anda dapat menggunakan *holdout validation*.  Anda memisahkan sebagian dari *training set* sebagai *validation set* (atau *development set* / *dev set*).  Latih beberapa model dengan berbagai *hyperparameter* pada *training set* yang dikurangi (tanpa *validation set*), dan pilih model yang berkinerja terbaik pada *validation set*.  Setelah proses ini, latih model terbaik pada seluruh *training set* (termasuk *validation set*), dan ini akan menjadi model final.  Terakhir, evaluasi model final ini pada *test set* untuk mendapatkan estimasi kesalahan generalisasi. 

Jika *validation set* terlalu kecil, evaluasi model bisa tidak tepat.  Jika terlalu besar, *training set* yang tersisa akan jauh lebih kecil, yang tidak ideal karena model final dilatih pada *training set* penuh.  Solusi untuk masalah ini adalah melakukan *repeated cross-validation*, menggunakan banyak *validation set* kecil. 

### 5.3. Data Mismatch

Dalam beberapa kasus, mudah untuk mendapatkan sejumlah besar data untuk pelatihan, tetapi data ini mungkin tidak sepenuhnya representatif untuk data yang akan digunakan dalam produksi. 

Solusi: *Validation set* dan *test set* harus se-representatif mungkin dari data yang Anda harapkan akan digunakan dalam produksi.  Jika kinerja pada *validation set* mengecewakan, tetapi model berkinerja baik pada *train-dev set* (sebagian data pelatihan yang dipisahkan), masalahnya mungkin berasal dari *data mismatch*.  Anda dapat mencoba mengatasi ini dengan melakukan *preprocessing* pada data pelatihan agar lebih mirip dengan data produksi.  Jika model berkinerja buruk pada *train-dev set*, berarti model telah *overfitting* *training set*, dan Anda harus menyederhanakan atau meregulasi model, mendapatkan lebih banyak data pelatihan, dan membersihkan data pelatihan. 

### 5.4. No Free Lunch Theorem

Menurut *No Free Lunch (NFL) theorem* (David Wolpert, 1996), jika Anda sama sekali tidak membuat asumsi tentang data, maka tidak ada alasan untuk lebih memilih satu model daripada yang lain.  Setiap model memiliki keunggulan dan kelemahan, dan tidak ada model yang secara *a priori* dijamin akan bekerja lebih baik daripada yang lain.  Dalam praktiknya, Anda membuat beberapa asumsi yang masuk akal tentang data dan mengevaluasi hanya beberapa model yang masuk akal. 

---

## 6. Ringkasan Bab 1

* **Machine Learning** adalah tentang membuat mesin menjadi lebih baik dalam suatu tugas dengan belajar dari data, alih-alih harus secara eksplisit mengkodekan aturan. 
* Ada berbagai jenis sistem ML: *supervised* atau tidak, *batch* atau *online*, *instance-based* atau *model-based*. 
* Dalam proyek ML, Anda mengumpulkan data dalam *training set*, dan Anda memberikan *training set* tersebut ke algoritma pembelajaran. 
* Sistem tidak akan berkinerja baik jika *training set* Anda terlalu kecil, atau jika datanya tidak representatif, berisik, atau terkontaminasi dengan fitur yang tidak relevan (*garbage in, garbage out*). 
* Model Anda tidak boleh terlalu sederhana (*underfit*) atau terlalu kompleks (*overfit*). 
* Setelah melatih model, penting untuk mengevaluasinya pada kasus-kasus baru menggunakan *test set* untuk mengestimasi *generalization error*. 

**Penting:** Sebelum melanjutkan ke bab-bab berikutnya yang akan lebih banyak membahas kode, pastikan Anda memahami semua konsep dasar yang dijelaskan dalam bab ini. Jika ada pertanyaan, jangan ragu untuk bertanya!

---
