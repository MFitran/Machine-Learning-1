{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bab 3: Klasifikasi\n",
    "\n",
    "Dalam bab ini, kita akan mendalami konsep-konsep inti klasifikasi dalam Machine Learning. Klasifikasi adalah tugas Machine Learning supervised di mana tujuannya adalah untuk memprediksi kelas atau kategori suatu input. Kita akan mempelajari berbagai metrik evaluasi untuk classifier, serta trade-off penting antara presisi dan recall.\n",
    "\n",
    "Referensi utama bab ini adalah buku *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems* (O’Reilly) oleh Aurélien Géron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 MNIST\n",
    "\n",
    "Dataset MNIST adalah \"hello world\" di dunia Machine Learning untuk tugas klasifikasi gambar. Dataset ini terdiri dari 70.000 gambar kecil (28x28 piksel) tulisan tangan digit (0-9) yang dikumpulkan dari siswa sekolah menengah dan karyawan Biro Sensus AS. Setiap gambar diberi label dengan digit yang diwakilinya.\n",
    "\n",
    "Dataset ini sangat populer untuk pengujian dan perbandingan algoritma klasifikasi baru. Kita akan menggunakannya untuk melatih dan mengevaluasi model klasifikasi kita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memuat Dataset MNIST\n",
    "\n",
    "Scikit-Learn menyediakan fungsi pembantu untuk mengunduh dataset populer, termasuk MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Memuat dataset MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False) # as_frame=False agar langsung NumPy array\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "print(f\"Bentuk data (X): {X.shape}\")\n",
    "print(f\"Bentuk target (y): {y.shape}\")\n",
    "print(f\"Tipe data target: {y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset yang dimuat oleh Scikit-Learn umumnya memiliki struktur kamus yang serupa, termasuk:\n",
    "* Kunci `DESCR` yang menjelaskan dataset.\n",
    "* Kunci `data` yang berisi array dengan satu baris per instance dan satu kolom per fitur.\n",
    "* Kunci `target` yang berisi array dengan label.\n",
    "\n",
    "Ada 70.000 gambar, dan setiap gambar memiliki 784 fitur. Ini karena setiap gambar adalah 28 × 28 piksel, dan setiap fitur hanya mewakili intensitas satu piksel, dari 0 (putih) hingga 255 (hitam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat Sekilas Satu Digit\n",
    "\n",
    "Mari kita lihat sekilas salah satu digit dari dataset. Kita hanya perlu mengambil vektor fitur sebuah instance, mengubah bentuknya menjadi array 28 × 28, dan menampilkannya menggunakan fungsi `imshow()` Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Label digit pertama: {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhatikan bahwa labelnya adalah string. Sebagian besar algoritma ML mengharapkan angka, jadi mari kita ubah `y` menjadi integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memisahkan Dataset Menjadi Set Pelatihan dan Pengujian\n",
    "\n",
    "Penting untuk selalu membuat set pengujian dan menyimpannya terpisah sebelum memeriksa data lebih dekat untuk menghindari bias pengintaian data (data snooping bias). Dataset MNIST sudah dibagi menjadi set pelatihan (60.000 gambar pertama) dan set pengujian (10.000 gambar terakhir).\n",
    "\n",
    "Set pelatihan sudah diacak, yang bagus karena ini menjamin bahwa semua *cross-validation folds* akan serupa. Selain itu, beberapa algoritma pembelajaran sensitif terhadap urutan instance pelatihan, dan mereka bekerja buruk jika mendapatkan banyak instance serupa berturut-turut. Mengacak dataset memastikan hal ini tidak akan terjadi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[60000:]\n",
    "\n",
    "print(f\"Bentuk X_train: {X_train.shape}\")\n",
    "print(f\"Bentuk y_train: {y_train.shape}\")\n",
    "print(f\"Bentuk X_test: {X_test.shape}\")\n",
    "print(f\"Bentuk y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Melatih Binary Classifier\n",
    "\n",
    "Mari kita sederhanakan masalah untuk saat ini dan hanya mencoba mengidentifikasi satu digit—misalnya, angka 5. \"Detektor-5\" ini akan menjadi contoh *binary classifier*, yang mampu membedakan antara dua kelas saja: 5 dan bukan-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat Target Vektor untuk Klasifikasi Biner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "print(f\"Contoh y_train_5: {y_train_5[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memilih dan Melatih Classifier\n",
    "\n",
    "Kita akan memilih *Stochastic Gradient Descent (SGD) classifier* menggunakan kelas `SGDClassifier` dari Scikit-Learn. Classifier ini memiliki keunggulan karena mampu menangani dataset yang sangat besar secara efisien, sebagian karena SGD menangani instance pelatihan secara independen, satu per satu, yang juga membuatnya cocok untuk *online learning*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melatih classifier, kita bisa menggunakannya untuk mendeteksi gambar angka 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_pred = sgd_clf.predict([some_digit])\n",
    "print(f\"Prediksi untuk some_digit (yang adalah 5): {some_digit_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Performance Measures (Pengukuran Kinerja)\n",
    "\n",
    "Mengevaluasi classifier seringkali jauh lebih rumit daripada mengevaluasi regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Measuring Accuracy Using Cross-Validation (Mengukur Akurasi Menggunakan Cross-Validation)\n",
    "\n",
    "Salah satu cara yang baik untuk mengevaluasi model adalah dengan menggunakan cross-validation, seperti yang Anda lakukan di Bab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Menggunakan cross_val_score untuk SGDClassifier\n",
    "scores = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "print(f\"Skor akurasi cross-validation: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil ini mungkin terlihat sangat tinggi (misalnya, di atas 93% akurasi). Namun, akurasi bukanlah ukuran kinerja yang disukai untuk classifier, terutama ketika Anda berhadapan dengan dataset yang miring (yaitu, ketika beberapa kelas jauh lebih sering daripada yang lain).\n",
    "\n",
    "Untuk menunjukkan ini, mari kita lihat classifier yang sangat sederhana yang selalu mengklasifikasikan setiap gambar dalam kelas \"bukan-5\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()\n",
    "never_5_scores = cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "print(f\"Skor akurasi Never5Classifier: {never_5_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier ini memiliki akurasi di atas 90% karena hanya sekitar 10% gambar yang merupakan angka 5. Jika Anda selalu menebak bahwa sebuah gambar bukan angka 5, Anda akan benar sekitar 90% dari waktu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Confusion Matrix\n",
    "\n",
    "Cara yang jauh lebih baik untuk mengevaluasi kinerja classifier adalah dengan melihat *confusion matrix*. Ide umumnya adalah menghitung berapa kali instance dari kelas A diklasifikasikan sebagai kelas B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "conf_mx = confusion_matrix(y_train_5, y_train_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setiap baris dalam confusion matrix mewakili kelas aktual, sedangkan setiap kolom mewakili kelas yang diprediksi.\n",
    "\n",
    "* Baris pertama (kelas negatif, \"bukan-5\"):\n",
    "    * **True Negatives (TN):** Jumlah instance yang diklasifikasikan dengan benar sebagai bukan-5.\n",
    "    * **False Positives (FP):** Jumlah instance yang salah diklasifikasikan sebagai 5.\n",
    "* Baris kedua (kelas positif, \"5\"):\n",
    "    * **False Negatives (FN):** Jumlah instance yang salah diklasifikasikan sebagai bukan-5.\n",
    "    * **True Positives (TP):** Jumlah instance yang diklasifikasikan dengan benar sebagai 5.\n",
    "\n",
    "Classifier yang sempurna hanya akan memiliki true positives dan true negatives, sehingga confusion matrix-nya hanya akan memiliki nilai bukan-nol pada diagonal utamanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh confusion matrix untuk classifier sempurna\n",
    "y_train_perfect_predictions = y_train_5  # Pura-pura mencapai kesempurnaan\n",
    "perfect_conf_mx = confusion_matrix(y_train_5, y_train_perfect_predictions)\n",
    "print(\"\\nConfusion Matrix (Sempurna):\")\n",
    "print(perfect_conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Precision and Recall (Presisi dan Recall)\n",
    "\n",
    "Salah satu yang menarik untuk dilihat adalah akurasi prediksi positif; ini disebut *precision* (presisi) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_train_5, y_train_pred)\n",
    "recall = recall_score(y_train_5, y_train_pred)\n",
    "\n",
    "print(f\"\\nPresisi: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seringkali nyaman untuk menggabungkan presisi dan recall ke dalam satu metrik yang disebut *F1 score*, terutama jika Anda memerlukan cara sederhana untuk membandingkan dua classifier. F1 score adalah *harmonic mean* dari presisi dan recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_train_5, y_train_pred)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Precision/Recall Trade-off (Trade-off Presisi/Recall)\n",
    "\n",
    "Sayangnya, Anda tidak bisa mendapatkan keduanya: meningkatkan presisi mengurangi recall, dan sebaliknya. Ini disebut *precision/recall trade-off*.\n",
    "\n",
    "Classifier seperti `SGDClassifier` membuat keputusan klasifikasinya berdasarkan fungsi keputusan. Jika skor dari fungsi keputusan ini lebih besar dari ambang batas tertentu, ia menetapkan instance ke kelas positif; jika tidak, ia menetapkannya ke kelas negatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "print(f\"Skor keputusan untuk some_digit: {y_scores}\")\n",
    "\n",
    "threshold = 0\n",
    "y_some_digit_pred_thresh0 = (y_scores > threshold)\n",
    "print(f\"Prediksi dengan ambang batas 0: {y_some_digit_pred_thresh0}\")\n",
    "\n",
    "threshold = 8000\n",
    "y_some_digit_pred_thresh8k = (y_scores > threshold)\n",
    "print(f\"Prediksi dengan ambang batas 8000: {y_some_digit_pred_thresh8k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk memutuskan ambang batas mana yang akan digunakan, kita bisa menggunakan fungsi `precision_recall_curve()` untuk menghitung presisi dan recall untuk semua kemungkinan ambang batas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_scores_train = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores_train)\n",
    "\n",
    "# Plot presisi dan recall sebagai fungsi dari nilai ambang batas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"center left\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Precision and Recall vs. Decision Threshold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cara lain untuk memilih trade-off presisi/recall yang baik adalah dengan memplot presisi langsung terhadap recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Precision vs. Recall Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 The ROC Curve (Kurva ROC)\n",
    "\n",
    "Kurva *Receiver Operating Characteristic (ROC)* adalah alat umum lainnya yang digunakan dengan classifier biner. Kurva ROC memplot *true positive rate (TPR)* (recall) terhadap *false positive rate (FPR)*. FPR adalah rasio instance negatif yang salah diklasifikasikan sebagai positif. Ini sama dengan 1 – *true negative rate (TNR)*, yang merupakan rasio instance negatif yang diklasifikasikan dengan benar sebagai negatif (TNR juga disebut *specificity*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_train_5, y_scores_train)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=\"SGD Classifier\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier\") # Dashed diagonal\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR) / Recall\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salah satu cara untuk membandingkan classifier adalah dengan mengukur *area under the curve (AUC)*. Classifier yang sempurna akan memiliki ROC AUC sama dengan 1, sedangkan classifier yang sepenuhnya acak akan memiliki ROC AUC sama dengan 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_train_5, y_scores_train)\n",
    "print(f\"ROC AUC Score (SGDClassifier): {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita latih `RandomForestClassifier` dan bandingkan kurva ROC dan skor ROC AUC-nya dengan `SGDClassifier`. `RandomForestClassifier` tidak memiliki metode `decision_function()`, melainkan metode `predict_proba()`. Metode `predict_proba()` mengembalikan array yang berisi baris per instance dan kolom per kelas, masing-masing berisi probabilitas bahwa instance yang diberikan termasuk dalam kelas yang diberikan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3, method=\"predict_proba\")\n",
    "\n",
    "# Kita gunakan probabilitas kelas positif sebagai skor\n",
    "y_scores_forest = y_probas_forest[:, 1]\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)\n",
    "\n",
    "# Plot perbandingan kurva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SGD Classifier\")\n",
    "plt.plot(fpr_forest, tpr_forest, linewidth=2, label=\"Random Forest Classifier\")\n",
    "plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR) / Recall\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.show()\n",
    "\n",
    "roc_auc_forest = roc_auc_score(y_train_5, y_scores_forest)\n",
    "print(f\"ROC AUC Score (RandomForestClassifier): {roc_auc_forest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Multiclass Classification (Klasifikasi Multikelas)\n",
    "\n",
    "Sementara classifier biner membedakan antara dua kelas, *multiclass classifiers* (juga disebut *multinomial classifiers*) dapat membedakan antara lebih dari dua kelas.\n",
    "\n",
    "Beberapa algoritma (seperti classifier SGD, classifier Random Forest, dan classifier Naive Bayes) mampu menangani banyak kelas secara native. Yang lain (seperti Logistic Regression atau Support Vector Machine classifiers) adalah classifier biner. Namun, ada berbagai strategi yang dapat Anda gunakan untuk melakukan klasifikasi multikelas dengan beberapa classifier biner.\n",
    "\n",
    "* **One-versus-the-rest (OvR) / One-versus-all:** Latih 10 classifier biner, satu untuk setiap digit (detektor-0, detektor-1, detektor-2, dan seterusnya). Ketika Anda ingin mengklasifikasikan sebuah gambar, Anda mendapatkan skor keputusan dari setiap classifier untuk gambar itu dan Anda memilih kelas yang classifier-nya menghasilkan skor tertinggi.\n",
    "* **One-versus-one (OvO):** Latih classifier biner untuk setiap pasangan digit: satu untuk membedakan 0s dan 1s, satu lagi untuk membedakan 0s dan 2s, satu lagi untuk 1s dan 2s, dan seterusnya. Jika ada N kelas, Anda perlu melatih N × (N – 1) / 2 classifier.\n",
    "\n",
    "Scikit-Learn mendeteksi ketika Anda mencoba menggunakan algoritma klasifikasi biner untuk tugas klasifikasi multikelas, dan secara otomatis menjalankan OvR atau OvO, tergantung pada algoritma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Melatih SVC pada training set menggunakan kelas target asli (y_train)\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train, y_train) # y_train, bukan y_train_5\n",
    "\n",
    "# Prediksi untuk some_digit\n",
    "some_digit_pred_multiclass = svm_clf.predict([some_digit])\n",
    "print(f\"Prediksi SVC untuk some_digit: {some_digit_pred_multiclass}\")\n",
    "\n",
    "# Melihat skor keputusan (10 skor per instance, satu per kelas)\n",
    "some_digit_scores = svm_clf.decision_function([some_digit])\n",
    "print(f\"Skor keputusan SVC untuk some_digit: {some_digit_scores}\")\n",
    "print(f\"Kelas dengan skor tertinggi: {np.argmax(some_digit_scores)}\")\n",
    "print(f\"Daftar kelas: {svm_clf.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melatih `SGDClassifier` (atau `RandomForestClassifier`) sama mudahnya, dan mereka dapat langsung mengklasifikasikan instance ke dalam banyak kelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih SGDClassifier untuk klasifikasi multikelas\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "sgd_digit_pred_multiclass = sgd_clf.predict([some_digit])\n",
    "print(f\"Prediksi SGDClassifier untuk some_digit: {sgd_digit_pred_multiclass}\")\n",
    "\n",
    "# Mengevaluasi akurasi SGDClassifier menggunakan cross-validation\n",
    "sgd_multiclass_scores = cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(f\"Skor akurasi multikelas SGDClassifier: {sgd_multiclass_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi di atas 84% pada semua *test folds* tidak terlalu buruk, tetapi kita masih bisa melakukan yang lebih baik. Menskalakan input (seperti yang dibahas di Bab 2) meningkatkan akurasi di atas 89%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "\n",
    "sgd_scaled_scores = cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(f\"Skor akurasi multikelas SGDClassifier (scaled): {sgd_scaled_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Error Analysis (Analisis Kesalahan)\n",
    "\n",
    "Jika ini adalah proyek nyata, Anda sekarang akan mengikuti langkah-langkah dalam daftar periksa proyek Machine Learning Anda (lihat Apendiks B). Anda akan menjelajahi opsi persiapan data, mencoba beberapa model, dan menyempurnakan hyperparameter mereka. Di sini, kita akan mengasumsikan bahwa Anda telah menemukan model yang menjanjikan dan Anda ingin mencari cara untuk memperbaikinya. Salah satu cara untuk melakukannya adalah dengan menganalisis jenis kesalahan yang dibuatnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_scaled = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx_scaled = confusion_matrix(y_train, y_train_pred_scaled)\n",
    "\n",
    "plt.matshow(conf_mx_scaled, cmap=plt.cm.gray)\n",
    "plt.title(\"Confusion Matrix (Scaled Data)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix ini terlihat cukup bagus, karena sebagian besar gambar berada pada diagonal utama, yang berarti diklasifikasikan dengan benar. Angka 5 terlihat sedikit lebih gelap daripada digit lain, yang bisa berarti ada lebih sedikit gambar angka 5 dalam dataset atau bahwa classifier tidak bekerja sebaik pada angka 5 seperti pada digit lainnya.\n",
    "\n",
    "Untuk fokus pada kesalahan, kita bisa membagi setiap nilai dalam confusion matrix dengan jumlah gambar di kelas yang sesuai, sehingga kita dapat membandingkan tingkat kesalahan alih-alih jumlah kesalahan absolut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_mx_scaled.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx_scaled / row_sums\n",
    "\n",
    "# Isi diagonal dengan nol untuk hanya menyimpan kesalahan\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.title(\"Confusion Matrix (Errors Only, Normalized)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Multilabel Classification (Klasifikasi Multilabel)\n",
    "\n",
    "Hingga saat ini, setiap instance selalu ditetapkan ke hanya satu kelas. Dalam beberapa kasus, Anda mungkin ingin classifier Anda mengeluarkan banyak kelas untuk setiap instance. Sistem klasifikasi yang mengeluarkan banyak tag biner disebut *multilabel classification system*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Membuat target multilabel: digit besar (7, 8, atau 9) dan digit ganjil\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "\n",
    "# Melatih KNeighborsClassifier (yang mendukung klasifikasi multilabel)\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)\n",
    "\n",
    "# Prediksi untuk some_digit (yang adalah 5)\n",
    "some_digit_pred_multilabel = knn_clf.predict([some_digit])\n",
    "print(f\"Prediksi multilabel untuk some_digit (5): {some_digit_pred_multilabel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada banyak cara untuk mengevaluasi classifier multilabel. Salah satu pendekatan adalah mengukur F1 score untuk setiap label individual, lalu menghitung skor rata-rata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "f1_multilabel = f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")\n",
    "print(f\"F1 Score (multilabel, average='macro'): {f1_multilabel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Multioutput Classification (Klasifikasi Multioutput)\n",
    "\n",
    "Jenis tugas klasifikasi terakhir yang akan kita bahas di sini disebut *multioutput-multiclass classification* (atau hanya *multioutput classification*). Ini hanyalah generalisasi dari klasifikasi multilabel di mana setiap label dapat berupa multikelas (yaitu, dapat memiliki lebih dari dua nilai yang mungkin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat training dan test set dengan menambahkan noise pada gambar MNIST\n",
    "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "X_train_mod = X_train + noise\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "X_test_mod = X_test + noise\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test\n",
    "\n",
    "# Fungsi untuk memplot digit (dari notebook asli)\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Melihat contoh gambar ber-noise dan target bersih\n",
    "some_index = 0\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Noisy Image\")\n",
    "plot_digit(X_test_mod[some_index])\n",
    "plt.subplot(122)\n",
    "plt.title(\"Clean Target\")\n",
    "plot_digit(y_test_mod[some_index])\n",
    "plt.show()\n",
    "\n",
    "# Melatih classifier dan membersihkan gambar\n",
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit_pred = knn_clf.predict([X_test_mod[some_index]])\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Cleaned Image Prediction\")\n",
    "plot_digit(clean_digit_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat cukup dekat dengan target! Ini mengakhiri tur kita dalam klasifikasi. Anda sekarang harus tahu cara memilih metrik yang baik untuk tugas klasifikasi, memilih trade-off presisi/recall yang sesuai dengan kebutuhan Anda, membandingkan classifier, dan secara lebih umum membangun sistem klasifikasi yang baik untuk berbagai tugas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
