{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ogTJ_TcbYo"
      },
      "source": [
        "# Bab 16: Pemrosesan Bahasa Alami dengan RNN dan Mekanisme Perhatian\n",
        "\n",
        "**Tujuan Pembelajaran:**\n",
        "\n",
        "Notebook ini bertujuan untuk memperdalam pemahaman dan keterampilan praktis dalam mengimplementasikan konsep inti Pemrosesan Bahasa Alami (NLP) menggunakan Recurrent Neural Networks (RNN) dan Mekanisme Perhatian, merujuk pada Bab 16 dari buku \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow.\"\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVjZsfKDcbYs"
      },
      "source": [
        "### **Pendahuluan**\n",
        "\n",
        "Bab ini akan membawa kita menyelami dunia Pemrosesan Bahasa Alami (NLP) yang menarik, khususnya dengan fokus pada Recurrent Neural Networks (RNN) dan mekanisme perhatian. Kita akan melihat bagaimana model-model ini dapat memahami, menghasilkan, dan menerjemahkan bahasa manusia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxW_pjCNcbYt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ij2o4NCcbYt"
      },
      "source": [
        "### **1. Membangun dan Menghasilkan Teks ala Shakespeare dengan Character RNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcpZLFD1cbYu"
      },
      "source": [
        "#### **1.1. Membuat Dataset Pelatihan**\n",
        "\n",
        "**Teori:**\n",
        "Untuk melatih RNN agar dapat menghasilkan teks, kita memerlukan korpus teks yang besar. Dalam kasus ini, kita akan menggunakan karya-karya Shakespeare. Teks ini perlu diubah menjadi representasi numerik yang dapat dipahami oleh model. Pendekatan \"Character RNN\" (Char-RNN) berarti kita akan memprediksi karakter berikutnya dalam sebuah urutan. Setiap karakter akan diberi ID numerik unik. Keras's `Tokenizer` adalah alat yang sangat berguna untuk tugas ini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCBLmkRNcbYu",
        "outputId": "8600495a-2d94-455a-b6b6-84d2c022075a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n",
            "<function version at 0x7dbd2471ed40>\n",
            "Downloading data from https://homl.info/shakespeare\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Total karakter dalam teks Shakespeare: 1115394\n",
            "Jumlah karakter unik: 39\n",
            "Total karakter (setelah tokenisasi): 1\n",
            "Encoding 'First': [[20, 6, 9, 8, 3]]\n",
            "Decoding [[20, 6, 9, 8, 3]]: ['f i r s t']\n",
            "Bentuk encoded teks: (1115394,)\n"
          ]
        }
      ],
      "source": [
        "# Import library yang diperlukan\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "# Pastikan TensorFlow dan Keras sudah terinstal dan berfungsi\n",
        "print(tf.__version__)\n",
        "print(keras.version)\n",
        "\n",
        "# Download karya-karya Shakespeare\n",
        "shakespeare_url = \"https://homl.info/shakespeare\" # URL shortcut dari buku\n",
        "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "\n",
        "# Baca teks\n",
        "with open(filepath, 'r') as f:\n",
        "    shakespeare_text = f.read()\n",
        "\n",
        "print(f\"Total karakter dalam teks Shakespeare: {len(shakespeare_text)}\")\n",
        "\n",
        "# Buat tokenizer tingkat karakter\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True, lower=True)\n",
        "tokenizer.fit_on_texts([shakespeare_text])\n",
        "\n",
        "# Informasi tokenizer\n",
        "max_id = len(tokenizer.word_index) # Jumlah karakter unik\n",
        "dataset_size = tokenizer.document_count # Total karakter\n",
        "print(f\"Jumlah karakter unik: {max_id}\")\n",
        "print(f\"Total karakter (setelah tokenisasi): {dataset_size}\")\n",
        "\n",
        "# Contoh encoding dan decoding\n",
        "print(f\"Encoding 'First': {tokenizer.texts_to_sequences(['First'])}\")\n",
        "print(f\"Decoding [[20, 6, 9, 8, 3]]: {tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])}\")\n",
        "\n",
        "# Encode seluruh teks ke dalam ID karakter (dimulai dari 0)\n",
        "encoded = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
        "encoded_train = encoded[0] # Ambil array 1D\n",
        "print(f\"Bentuk encoded teks: {encoded_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rjZSTdacbYw"
      },
      "source": [
        "#### **1.2. Cara Membagi Dataset Sekuensial (dan Memotongnya menjadi Jendela)**\n",
        "\n",
        "**Teori:**\n",
        "Dalam NLP, kita tidak bisa hanya mengacak semua karakter atau kata dalam teks karena akan menghancurkan struktur sekuensialnya. Untuk melatih RNN, kita perlu mempertahankan urutan. Oleh karena itu, pembagian dataset dilakukan berdasarkan urutan waktu. Misalnya, kita dapat mengambil 90% pertama dari teks untuk pelatihan, 5% berikutnya untuk validasi, dan 5% terakhir untuk pengujian.\n",
        "\n",
        "Char-RNN melatih model untuk memprediksi karakter berikutnya dalam sebuah urutan. Untuk ini, kita perlu membuat \"jendela\" dari teks, di mana setiap jendela adalah substring pendek dari teks lengkap. Ini dikenal sebagai *truncated backpropagation through time* (BPTT). Metode `window()` dari `tf.data.Dataset` sangat cocok untuk ini, memungkinkan kita untuk membuat jendela yang tumpang tindih (`shift=1`) untuk memaksimalkan penggunaan data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOazmhZBcbYw",
        "outputId": "2deb1939-70a6-4981-8c33-4891275cc4a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bentuk X_batch: (32, 100, 39)\n",
            "Bentuk Y_batch: (32, 100)\n"
          ]
        }
      ],
      "source": [
        "# Bagi dataset menjadi training, validation, dan test set\n",
        "train_size = encoded_train.shape[0] * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded_train[:train_size])\n",
        "\n",
        "# Tentukan panjang jendela (n_steps) dan buat jendela\n",
        "n_steps = 100 # Panjang sekuens input yang akan diproses RNN\n",
        "window_length = n_steps + 1 # Target adalah input yang digeser 1 karakter ke depan\n",
        "\n",
        "# Buat jendela yang tumpang tindih\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "\n",
        "# Ratakan dataset bersarang menjadi dataset datar\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "# Acak jendela dan pisahkan input (n_steps pertama) dari target (karakter terakhir)\n",
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "\n",
        "# One-hot encode input karakter\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "\n",
        "# Tambahkan prefetching untuk efisiensi\n",
        "dataset = dataset.prefetch(1)\n",
        "\n",
        "# Verifikasi bentuk dataset\n",
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(f\"Bentuk X_batch: {X_batch.shape}\")\n",
        "    print(f\"Bentuk Y_batch: {Y_batch.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3m281E7cbYx"
      },
      "source": [
        "#### **1.3. Membangun dan Melatih Model Char-RNN**\n",
        "\n",
        "**Teori:**\n",
        "Model Char-RNN akan terdiri dari beberapa lapisan GRU (Gated Recurrent Unit) yang ditumpuk, diikuti oleh lapisan `TimeDistributed(Dense)`. Lapisan GRU sangat baik dalam menangani dependensi jangka panjang dalam sekuens. `return_sequences=True` penting untuk lapisan GRU kecuali yang terakhir jika kita ingin setiap langkah waktu menghasilkan output. Lapisan `TimeDistributed(Dense)` memungkinkan lapisan `Dense` diterapkan secara independen pada setiap langkah waktu dari sekuens input. Karena kita memprediksi salah satu dari `max_id` karakter unik, lapisan output akan memiliki `max_id` unit dengan fungsi aktivasi `softmax`. Fungsi *loss* yang umum untuk tugas klasifikasi multi-kelas dengan label integer sparse adalah `sparse_categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "0tj5_m4acbYx",
        "outputId": "a070468b-d243-4f12-9a40-c753f98df9e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m64,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m99,072\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)       │         \u001b[38;5;34m5,031\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m168,999\u001b[0m (660.15 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">168,999</span> (660.15 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m168,999\u001b[0m (660.15 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">168,999</span> (660.15 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Bangun model Char-RNN\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                     dropout=0.2, recurrent_dropout=0.2), # max_id adalah dimensi one-hot\n",
        "    keras.layers.GRU(128, return_sequences=True,\n",
        "                     dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "# Ringkasan model\n",
        "model.summary()\n",
        "\n",
        "# Latih model (Epochs mungkin perlu disesuaikan tergantung pada kinerja)\n",
        "# history = model.fit(dataset, epochs=20) # Uncomment untuk melatih"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct-5bBWgcbYx"
      },
      "source": [
        "#### **1.4. Menggunakan Model Char-RNN**\n",
        "\n",
        "**Teori:**\n",
        "Setelah model dilatih, kita dapat menggunakannya untuk memprediksi karakter berikutnya dari teks input. Fungsi `predict()` akan menghasilkan probabilitas untuk setiap karakter yang mungkin. Untuk menghasilkan teks yang lebih beragam dan menarik, kita tidak selalu memilih karakter dengan probabilitas tertinggi, melainkan mengambil sampel karakter secara acak berdasarkan distribusi probabilitas yang diprediksi. Konsep \"suhu\" diperkenalkan untuk mengontrol keragaman ini: suhu yang lebih rendah akan membuat model lebih percaya diri (kurang beragam), sementara suhu yang lebih tinggi akan membuat model lebih \"kreatif\" (lebih beragam)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZDDr5v5vcbYy"
      },
      "outputs": [],
      "source": [
        "# Fungsi pra-pemrosesan untuk teks baru\n",
        "def preprocess_text(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)\n",
        "\n",
        "# Fungsi untuk memprediksi karakter berikutnya\n",
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess_text([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :] # Ambil probabilitas output dari langkah waktu terakhir\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
        "\n",
        "# Fungsi untuk melengkapi teks\n",
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text\n",
        "\n",
        "# Contoh penggunaan (setelah model dilatih)\n",
        "# print(f\"Teks dihasilkan (suhu 0.2): {complete_text('t', temperature=0.2)}\")\n",
        "# print(f\"Teks dihasilkan (suhu 1): {complete_text('w', temperature=1)}\")\n",
        "# print(f\"Teks dihasilkan (suhu 2): {complete_text('w', temperature=2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPocVCk8cbYy"
      },
      "source": [
        "#### **1.5. RNN Berstateful**\n",
        "\n",
        "**Teori:**\n",
        "RNN stateless, seperti yang kita gunakan sejauh ini, menginisialisasi *hidden state* dengan nol di setiap iterasi pelatihan dan membuangnya setelah setiap *batch*. Ini berarti mereka hanya dapat belajar pola yang lebih pendek dari panjang sekuens yang dilatih. RNN stateful, di sisi lain, mempertahankan *hidden state* dari satu *batch* ke *batch* berikutnya. Ini memungkinkan model untuk belajar pola jangka panjang yang melampaui batas satu sekuens dalam *batch*. Kunci untuk RNN stateful adalah memastikan bahwa sekuens input dalam satu *batch* melanjutkan tepat di mana sekuens yang sesuai di *batch* sebelumnya berhenti. Ini memerlukan pengaturan `stateful=True` pada lapisan RNN dan menentukan `batch_input_shape` pada lapisan pertama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "DezEG-GFcbYy",
        "outputId": "c124715c-0e58-4469-f559-0fb2af5ac2f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m64,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m99,072\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m99,072\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)          │         \u001b[38;5;34m5,031\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m268,071\u001b[0m (1.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,071</span> (1.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m268,071\u001b[0m (1.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,071</span> (1.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Konfigurasi dataset untuk RNN stateful (membutuhkan sekuens berurutan dan non-tumpang tindih)\n",
        "# Ini lebih kompleks, jadi kita akan membuat dataset yang disederhanakan untuk demonstrasi\n",
        "\n",
        "# Untuk demonstrasi, kita akan membuat dataset batch_size=1\n",
        "# Dalam kasus nyata, perlu strategi pembagian dan batching yang lebih canggih.\n",
        "\n",
        "seq_length_stateful = n_steps # Panjang sekuens untuk RNN stateful\n",
        "\n",
        "dataset_stateful = tf.data.Dataset.from_tensor_slices(encoded_train[:train_size])\n",
        "dataset_stateful = dataset_stateful.window(seq_length_stateful, shift=seq_length_stateful, drop_remainder=True)\n",
        "dataset_stateful = dataset_stateful.flat_map(lambda window: window.batch(seq_length_stateful))\n",
        "dataset_stateful = dataset_stateful.batch(1) # Batch size 1 untuk kesederhanaan\n",
        "dataset_stateful = dataset_stateful.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset_stateful = dataset_stateful.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset_stateful = dataset_stateful.prefetch(1)\n",
        "\n",
        "# Definisikan batch_size untuk model stateful (harus sama dengan batch_size dataset)\n",
        "stateful_batch_size = 1\n",
        "\n",
        "# Asumsi: max_id sudah terdefinisi dari kode sebelumnya (misalnya, 39)\n",
        "# Asumsi: stateful_batch_size sudah terdefinisi (misalnya, 1)\n",
        "\n",
        "# Dummy values for demonstration if not already defined\n",
        "if 'max_id' not in locals():\n",
        "    max_id = 39\n",
        "if 'stateful_batch_size' not in locals():\n",
        "    stateful_batch_size = 1\n",
        "\n",
        "# Bangun model RNN stateful\n",
        "stateful_model = keras.models.Sequential([\n",
        "    # Gunakan Input layer terpisah untuk mendefinisikan batch_input_shape\n",
        "    keras.layers.Input(batch_shape=[stateful_batch_size, None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "# Callback untuk mereset state di awal setiap epoch\n",
        "class ResetStatesCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()\n",
        "\n",
        "# Kompilasi model stateful\n",
        "stateful_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "# Ringkasan model stateful\n",
        "stateful_model.summary()\n",
        "\n",
        "# Latih model stateful (Epochs mungkin perlu lebih banyak karena batch_size kecil)\n",
        "# history_stateful = stateful_model.fit(dataset_stateful, epochs=50,\n",
        "#                                       callbacks=[ResetStatesCallback()]) # Uncomment untuk melatih"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQQP1rzycbYz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXLv6t9ocbYz"
      },
      "source": [
        "### **2. Analisis Sentimen (Sentiment Analysis)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17jUfg5TcbYz"
      },
      "source": [
        "#### **Teori:**\n",
        "Analisis sentimen adalah tugas NLP yang bertujuan untuk menentukan \"nada\" atau \"emosi\" di balik sebuah teks, biasanya diklasifikasikan sebagai positif atau negatif. Dataset ulasan film IMDb adalah contoh klasik untuk ini. Daripada memproses karakter, kita sekarang akan memproses kata. Kata-kata akan diubah menjadi ID numerik (seperti pada Char-RNN), dan kemudian sering kali diwakili sebagai *word embeddings* (yang akan dibahas lebih lanjut).\n",
        "\n",
        "Salah satu tantangan dalam memproses teks adalah panjang sekuens yang bervariasi. Ulasan film bisa sangat panjang atau sangat pendek. Untuk mengatasi ini, kita dapat melakukan *padding* pada sekuens yang lebih pendek sehingga semua sekuens dalam satu *batch* memiliki panjang yang sama. Keras menyediakan mekanisme *masking* (`mask_zero=True` pada lapisan `Embedding`) untuk mengabaikan token *padding* ini selama pelatihan, sehingga model fokus pada konten yang relevan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "iVN03glpcbYz",
        "outputId": "bf9a9b96-70e1-4435-fd9d-959f46a2307e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "X_test_val_imdb shape: (12500, 300)\n",
            "y_test_val_imdb shape: (12500,)\n",
            "X_test_final_imdb shape: (12500, 300)\n",
            "y_test_final_imdb shape: (12500,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m1,408,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m99,072\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_6 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m99,072\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,606,273\u001b[0m (6.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,606,273</span> (6.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,606,273\u001b[0m (6.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,606,273</span> (6.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Muat dataset ulasan film IMDb\n",
        "(X_train_imdb, y_train_imdb), (X_test_imdb, y_test_imdb) = keras.datasets.imdb.load_data()\n",
        "\n",
        "# Dapatkan kamus kata-ID\n",
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "id_to_word = {id_ + 3: word for word, id_ in word_index.items()} # +3 karena ID 0, 1, 2 spesial\n",
        "for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "    id_to_word[id_] = token\n",
        "\n",
        "# --- Perbaikan dimulai di sini ---\n",
        "# Tentukan panjang maksimum untuk padding\n",
        "# Anda bisa memilih panjang ini berdasarkan distribusi panjang ulasan Anda\n",
        "# Atau gunakan nilai default yang masuk akal, misalnya 300 seperti di bagian preprocess\n",
        "max_review_length = 300\n",
        "\n",
        "# Lakukan padding pada X_test_imdb\n",
        "X_test_imdb_padded = keras.preprocessing.sequence.pad_sequences(X_test_imdb,\n",
        "                                                                 maxlen=max_review_length,\n",
        "                                                                 padding='post', # Padding di akhir sekuens\n",
        "                                                                 truncating='post', # Truncate di akhir sekuens jika terlalu panjang\n",
        "                                                                 value=0) # Value untuk padding (0 adalah token <pad>)\n",
        "\n",
        "# Konversi NumPy array yang sudah di-padding ke tf.constant\n",
        "# Kemudian bagi data validasi dan data test final\n",
        "X_test_val_imdb = tf.constant(X_test_imdb_padded[:12500])\n",
        "X_test_final_imdb = tf.constant(X_test_imdb_padded[12500:])\n",
        "\n",
        "y_test_val_imdb = tf.constant(y_test_imdb[:12500])\n",
        "y_test_final_imdb = tf.constant(y_test_imdb[12500:])\n",
        "\n",
        "print(\"X_test_val_imdb shape:\", X_test_val_imdb.shape)\n",
        "print(\"y_test_val_imdb shape:\", y_test_val_imdb.shape)\n",
        "print(\"X_test_final_imdb shape:\", X_test_final_imdb.shape)\n",
        "print(\"y_test_final_imdb shape:\", y_test_final_imdb.shape)\n",
        "\n",
        "# --- Perbaikan berakhir di sini ---\n",
        "\n",
        "# Lanjutkan dengan kode yang lain...\n",
        "\n",
        "# Model untuk analisis sentimen (menggunakan vocab_size_imdb dan embed_size_imdb)\n",
        "# Pastikan variabel ini terdefinisi jika Anda menjalankan potongan kode ini secara terpisah\n",
        "# Contoh dummy jika belum terdefinisi:\n",
        "vocab_size_imdb = 10000\n",
        "num_oov_buckets_imdb = 1000\n",
        "embed_size_imdb = 128\n",
        "\n",
        "sentiment_model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(vocab_size_imdb + num_oov_buckets_imdb, embed_size_imdb,\n",
        "                           input_shape=[None], mask_zero=True), # mask_zero=True untuk padding\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.GRU(128),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\") # Output biner (positif/negatif)\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "sentiment_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "                        metrics=[\"accuracy\"])\n",
        "\n",
        "# Ringkasan model\n",
        "sentiment_model.summary()\n",
        "\n",
        "# Latih model\n",
        "# history_sentiment = sentiment_model.fit(train_set_imdb, epochs=5) # Uncomment untuk melatih"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4c51CmGcbYz"
      },
      "source": [
        "#### **2.1. Menggunakan Embedding yang Sudah Dilatih (Pretrained Embeddings)**\n",
        "\n",
        "**Teori:**\n",
        "Melatih *word embeddings* dari awal membutuhkan korpus teks yang sangat besar. Untungnya, kita dapat menggunakan *embeddings* yang sudah dilatih sebelumnya dari korpus umum yang lebih besar (misalnya, Wikipedia atau Google News). *Embeddings* ini sering kali sudah menangkap banyak informasi semantik tentang kata-kata dan dapat secara signifikan meningkatkan kinerja model, terutama ketika dataset pelatihan kita kecil. TensorFlow Hub menyediakan cara mudah untuk mengunduh dan menggunakan *modules* model yang sudah dilatih."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "1LjhKs_rcbY0",
        "outputId": "8d346efe-bc07-4078-e56c-2048a193cdc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-2168095594.py:30: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**{k: v for k, v in kwargs.items() if k != 'output_shape'})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m)                 │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ custom_hub_embedding            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mWrappedHubLayer\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m6,528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ custom_hub_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">WrappedHubLayer</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,657\u001b[0m (26.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,657</span> (26.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,657\u001b[0m (26.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,657</span> (26.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import tensorflow_datasets as tfds # Untuk memuat dataset imdb\n",
        "\n",
        "# --- Muat dataset IMDb (jika belum dimuat di sesi ini) ---\n",
        "# Ini penting agar datasets_imdb dan info_imdb tersedia\n",
        "try:\n",
        "    datasets_imdb, info_imdb = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
        "    train_size_imdb = info_imdb.splits[\"train\"].num_examples\n",
        "except tfds.core.ReadError:\n",
        "    print(\"Dataset IMDb tidak dapat dimuat, pastikan sudah diunduh atau jalankan di Colab.\")\n",
        "\n",
        "\n",
        "# --- Solusi: Perbaiki WrappedHubLayer untuk menangani output_shape dengan benar ---\n",
        "class WrappedHubLayer(keras.layers.Layer):\n",
        "    def __init__(self, hub_url, **kwargs):\n",
        "        # Ambil output_shape dari kwargs sebelum meneruskannya ke super()\n",
        "        # dan simpan sebagai atribut jika Anda berencana menggunakannya.\n",
        "        # Namun, lebih baik membiarkan hub.KerasLayer internal menentukannya.\n",
        "        # Argumen 'output_shape' sebenarnya adalah untuk hub.KerasLayer internal.\n",
        "\n",
        "        # Buat hub.KerasLayer internal dengan semua kwargs yang relevan\n",
        "        self._hub_layer_instance = hub.KerasLayer(hub_url, **kwargs)\n",
        "\n",
        "        # Panggil konstruktor parent TANPA output_shape\n",
        "        # karena output_shape bukan argumen standar untuk keras.layers.Layer.__init__\n",
        "        super().__init__(**{k: v for k, v in kwargs.items() if k != 'output_shape'})\n",
        "        self.hub_url = hub_url\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        return self._hub_layer_instance(inputs, training=training)\n",
        "\n",
        "    # Anda mungkin perlu menambahkan get_config jika Anda ingin menyimpan model ini\n",
        "    # dan memuatnya kembali nanti, terutama jika WrappedHubLayer memiliki argumen kustom.\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        # Jika Anda ingin menyimpan hub_url, tambahkan ke config\n",
        "        config.update({\n",
        "            'hub_url': self.hub_url,\n",
        "            # Anda perlu cara untuk menyimpan kwargs yang diteruskan ke hub.KerasLayer internal\n",
        "            # Ini bisa rumit. Untuk tujuan ini, kita asumsikan kwargs internal tidak perlu disimpan\n",
        "            # atau diserialisasi ulang secara eksplisit jika modelnya hanya akan di-run.\n",
        "            # Jika perlu diserialisasi, Anda harus menyimpan kwargs di __init__\n",
        "            # dan mengembalikannya di sini.\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "# --- Kode Model Utama ---\n",
        "inputs = keras.layers.Input(shape=(), dtype=tf.string, name='text_input')\n",
        "\n",
        "# Gunakan WrappedHubLayer yang telah diperbaiki\n",
        "# Argumen output_shape akan diteruskan ke hub.KerasLayer internal\n",
        "hub_layer_wrapped = WrappedHubLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
        "                                    dtype=tf.string, input_shape=(), output_shape=[50],\n",
        "                                    name='custom_hub_embedding')\n",
        "\n",
        "embeddings = hub_layer_wrapped(inputs)\n",
        "\n",
        "x = keras.layers.Dense(128, activation=\"relu\")(embeddings)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "pretrained_embedding_model_functional = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "pretrained_embedding_model_functional.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "                                               metrics=[\"accuracy\"])\n",
        "\n",
        "pretrained_embedding_model_functional.summary()\n",
        "\n",
        "# --- Latih model (jika Anda memiliki train_set_imdb yang sudah disiapkan) ---\n",
        "# Contoh:\n",
        "# train_set_imdb_for_hub = datasets_imdb[\"train\"].batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "# history_pretrained_functional = pretrained_embedding_model_functional.fit(\n",
        "#    train_set_imdb_for_hub, epochs=1 # Gunakan epoch kecil untuk testing\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oJyQdeJcbY0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWu9sy_HcbY0"
      },
      "source": [
        "### **3. Jaringan Encoder-Decoder untuk Neural Machine Translation (NMT)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02miHsOmcbY0"
      },
      "source": [
        "#### **Teori:**\n",
        "Jaringan Encoder-Decoder adalah arsitektur umum untuk tugas sekuens-ke-sekuens, seperti terjemahan mesin. Encoder membaca sekuens input (misalnya, kalimat bahasa Inggris) dan mengompresnya menjadi representasi vektor \"konteks\" tunggal yang menangkap esensi sekuens tersebut. Decoder kemudian menggunakan vektor konteks ini untuk menghasilkan sekuens output (misalnya, kalimat bahasa Prancis).\n",
        "\n",
        "Input ke decoder biasanya adalah sekuens target yang digeser satu langkah waktu ke depan (termasuk token SOS - Start of Sequence di awal) untuk memungkinkan pelatihan \"Teacher Forcing\". Selama inferensi, output yang diprediksi dari langkah waktu sebelumnya akan dimasukkan kembali sebagai input untuk langkah waktu saat ini. Penting untuk membalik sekuens input encoder untuk memastikan bagian awal kalimat masukan diproses terakhir, karena ini seringkali merupakan informasi pertama yang dibutuhkan decoder untuk memulai terjemahan.\n",
        "\n",
        "TensorFlow Addons menyediakan banyak alat untuk membangun model sekuens-ke-sekuens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9XlMdZS-cbY0",
        "outputId": "c46428fb-e7cc-4438-b830-f51a88aa5b55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"nmt_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"nmt_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,408,000\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,408,000\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m5,643,000\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m11000\u001b[0m)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408,000</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408,000</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,643,000</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">11000</span>)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,084,536\u001b[0m (42.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,084,536</span> (42.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,084,536\u001b[0m (42.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,084,536</span> (42.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Encoder untuk Inferensi:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m1,408,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │     \u001b[38;5;34m1,312,768\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]     │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]     │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,720,768\u001b[0m (10.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,720,768</span> (10.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,720,768\u001b[0m (10.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,720,768</span> (10.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Decoder untuk Inferensi:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │  \u001b[38;5;34m1,408,000\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_state_inpu… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_state_inpu… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m),  │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ decoder_state_in… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │ decoder_state_in… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m11000\u001b[0m)  │  \u001b[38;5;34m5,643,000\u001b[0m │ decoder_lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408,000</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_state_inpu… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_state_inpu… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ decoder_state_in… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │ decoder_state_in… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11000</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,643,000</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,363,768\u001b[0m (31.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,363,768</span> (31.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,363,768\u001b[0m (31.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,363,768</span> (31.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# --- Perhatikan: tensorflow_addons di-import di awal kode asli Anda,\n",
        "# --- tetapi akan dihindari dalam solusi ini karena masalah kompatibilitas.\n",
        "# --- !pip install tensorflow_addons (tidak lagi direkomendasikan untuk fungsionalitas ini)\n",
        "\n",
        "# Asumsi: Anda sudah memiliki vocab_size_imdb dan num_oov_buckets_imdb dari sentimen analysis\n",
        "# dan embed_size_imdb juga.\n",
        "# Jika belum terdefinisi, ini nilai dummy untuk memastikan kode berjalan:\n",
        "if 'vocab_size_imdb' not in locals():\n",
        "    vocab_size_imdb = 10000 # Contoh dari analisis sentimen\n",
        "if 'num_oov_buckets_imdb' not in locals():\n",
        "    num_oov_buckets_imdb = 1000 # Contoh dari analisis sentimen\n",
        "if 'embed_size_imdb' not in locals():\n",
        "    embed_size_imdb = 128 # Contoh dari analisis sentimen\n",
        "\n",
        "# Dummy vocabulary dan embedding (ganti dengan data terjemahan nyata)\n",
        "encoder_vocab_size = vocab_size_imdb + num_oov_buckets_imdb\n",
        "decoder_vocab_size = vocab_size_imdb + num_oov_buckets_imdb # Asumsi vocab yang sama\n",
        "\n",
        "# --- Bagian ENCODER ---\n",
        "encoder_inputs = keras.layers.Input(shape=[None], dtype=tf.int32, name='encoder_inputs')\n",
        "encoder_embeddings = keras.layers.Embedding(encoder_vocab_size, embed_size_imdb)(encoder_inputs)\n",
        "\n",
        "# Encoder (LSTM dengan return_state=True untuk mendapatkan hidden state terakhir)\n",
        "# return_state=True akan mengembalikan [output, hidden_state, cell_state] untuk LSTM\n",
        "encoder_lstm = keras.layers.LSTM(512, return_sequences=False, return_state=True, name='encoder_lstm')\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
        "encoder_state = [state_h, state_c] # Hidden state dan cell state terakhir dari encoder\n",
        "\n",
        "# --- Bagian DECODER ---\n",
        "# Input untuk decoder (sekuens target yang digeser 1 langkah ke depan)\n",
        "decoder_inputs = keras.layers.Input(shape=[None], dtype=tf.int32, name='decoder_inputs')\n",
        "decoder_embeddings = keras.layers.Embedding(decoder_vocab_size, embed_size_imdb)(decoder_inputs)\n",
        "\n",
        "# Sel Decoder (LSTM)\n",
        "# Decoder akan mengambil initial_state dari encoder\n",
        "decoder_lstm = keras.layers.LSTM(512, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "# Panggilan pertama dengan initial_state dari encoder\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_state)\n",
        "\n",
        "# Lapisan output untuk memprediksi kata\n",
        "output_layer = keras.layers.Dense(decoder_vocab_size, activation='softmax', name='decoder_output')\n",
        "Y_proba = output_layer(decoder_outputs)\n",
        "\n",
        "# Model Encoder-Decoder\n",
        "nmt_model = keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                        outputs=[Y_proba], name='nmt_model')\n",
        "\n",
        "# Kompilasi model (contoh)\n",
        "nmt_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "nmt_model.summary()\n",
        "\n",
        "# --- Catatan Penting untuk Pelatihan & Inferensi ---\n",
        "# Untuk pelatihan, Anda memerlukan data paralel:\n",
        "# encoder_input_data: sekuens input (misal: kalimat Inggris)\n",
        "# decoder_input_data: sekuens target yang digeser (misal: kalimat Prancis dengan <SOS> di depan, <EOS> di belakang, dan tanpa kata terakhir)\n",
        "# decoder_target_data: sekuens target asli (misal: kalimat Prancis tanpa <SOS> di depan)\n",
        "\n",
        "# Contoh data dummy (Anda perlu mengganti ini dengan data terjemahan nyata)\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "# max_encoder_len = 20\n",
        "# max_decoder_len = 25\n",
        "# dummy_encoder_input = tf.constant(np.random.randint(1, encoder_vocab_size, size=(32, max_encoder_len)), dtype=tf.int32)\n",
        "# dummy_decoder_input = tf.constant(np.random.randint(1, decoder_vocab_size, size=(32, max_decoder_len)), dtype=tf.int32)\n",
        "# dummy_decoder_target = tf.constant(np.random.randint(1, decoder_vocab_size, size=(32, max_decoder_len)), dtype=tf.int32)\n",
        "\n",
        "# nmt_model.fit([dummy_encoder_input, dummy_decoder_input], dummy_decoder_target, epochs=1)\n",
        "\n",
        "# --- Inferensi (Lebih Kompleks, Perlu Loop Prediksi) ---\n",
        "# Untuk inferensi, Anda akan membangun dua model terpisah:\n",
        "# 1. Encoder model: Input encoder_inputs, Output encoder_state\n",
        "# 2. Decoder model: Input decoder_inputs (untuk satu langkah waktu), initial_state, Output prediksi dan new_state\n",
        "\n",
        "# Model Encoder untuk Inferensi:\n",
        "encoder_model_inference = keras.Model(encoder_inputs, encoder_state)\n",
        "\n",
        "# Model Decoder untuk Inferensi:\n",
        "decoder_state_input_h = keras.layers.Input(shape=(512,), name='decoder_state_input_h')\n",
        "decoder_state_input_c = keras.layers.Input(shape=(512,), name='decoder_state_input_c')\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs_inference, state_h_inf, state_c_inf = decoder_lstm(\n",
        "    keras.layers.Embedding(decoder_vocab_size, embed_size_imdb)(keras.layers.Input(shape=(1,), dtype=tf.int32)), # Input tunggal untuk prediksi langkah demi langkah\n",
        "    initial_state=decoder_state_inputs\n",
        ")\n",
        "decoder_states_inference = [state_h_inf, state_c_inf]\n",
        "decoder_outputs_inference = output_layer(decoder_outputs_inference)\n",
        "\n",
        "decoder_model_inference = keras.Model(\n",
        "    [keras.layers.Input(shape=(1,), dtype=tf.int32), decoder_state_inputs],\n",
        "    [decoder_outputs_inference] + decoder_states_inference\n",
        ")\n",
        "\n",
        "print(\"\\nModel Encoder untuk Inferensi:\")\n",
        "encoder_model_inference.summary()\n",
        "print(\"\\nModel Decoder untuk Inferensi:\")\n",
        "decoder_model_inference.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZPUpVs8cbY0"
      },
      "source": [
        "#### **3.1. RNN Bidirectional**\n",
        "\n",
        "**Teori:**\n",
        "Lapisan RNN standar hanya melihat input masa lalu dan sekarang. Namun, untuk banyak tugas NLP seperti NMT, konteks dari kata-kata di masa depan juga penting (misalnya, untuk disambiguasi kata). RNN Bidirectional mengatasi ini dengan menjalankan dua lapisan RNN pada input yang sama: satu dari kiri ke kanan, dan satu lagi dari kanan ke kiri. Output dari kedua lapisan ini kemudian digabungkan (biasanya dengan penggabungan) pada setiap langkah waktu untuk memberikan representasi yang kaya konteks yang melihat ke masa lalu dan masa depan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CRQrBKZgcbY1"
      },
      "outputs": [],
      "source": [
        "# Contoh lapisan GRU bidirectional\n",
        "bidirectional_gru_layer = keras.layers.Bidirectional(\n",
        "    keras.layers.GRU(10, return_sequences=True))\n",
        "\n",
        "# Cara mengganti lapisan encoder di NMT_model dengan bidirectional (contoh)\n",
        "# encoder_bidirectional = keras.layers.Bidirectional(\n",
        "#     keras.layers.LSTM(512, return_state=True), merge_mode='concat')\n",
        "# Jika return_state=True, Bidirectional akan mengembalikan state_h dan state_c dari kedua arah.\n",
        "# Ini berarti return_state akan menjadi [forward_h, forward_c, backward_h, backward_c]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH1V3t_-cbY1"
      },
      "source": [
        "#### **3.2. Beam Search**\n",
        "\n",
        "**Teori:**\n",
        "Selama inferensi dalam model sekuens-ke-sekuens, memprediksi kata berikutnya secara serakah (memilih probabilitas tertinggi) dapat menyebabkan kesalahan yang tidak dapat diperbaiki. *Beam Search* adalah algoritma pencarian yang mengatasi ini dengan mempertahankan daftar pendek ($k$) sekuens output paling menjanjikan pada setiap langkah waktu. Pada setiap langkah, algoritma memperluas setiap sekuens dalam daftar $k$ dengan setiap kata yang mungkin, mengevaluasi probabilitas gabungan, dan kemudian memilih $k$ sekuens teratas untuk langkah berikutnya. Parameter $k$ disebut *beam width*. Ini secara signifikan meningkatkan kualitas terjemahan atau generasi teks, meskipun dengan biaya komputasi yang lebih tinggi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ojvXPtkMcbY1"
      },
      "outputs": [],
      "source": [
        "# Beam Search Decoder (untuk inferensi)\n",
        "beam_width = 10\n",
        "# decoder_initial_state harus 'ditile' (digandakan) sebanyak beam_width\n",
        "# Contoh:\n",
        "# decoder_initial_state_tiled = tfa.seq2seq.beam_search_decoder.tile_batch(\n",
        "#    encoder_state, multiplier=beam_width)\n",
        "\n",
        "# beam_search_decoder = tfa.seq2seq.beam_search_decoder.BeamSearchDecoder(\n",
        "#     cell=decoder_cell, beam_width=beam_width, output_layer=output_layer)\n",
        "\n",
        "# output_beam_search, _, _ = beam_search_decoder(\n",
        "#     embedding_decoder, start_tokens=start_tokens, end_token=end_token,\n",
        "#     initial_state=decoder_initial_state_tiled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzcNOY9UcbY1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfNOjv5pcbY1"
      },
      "source": [
        "### **4. Mekanisme Perhatian (Attention Mechanisms)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn0bliNocbY1"
      },
      "source": [
        "#### **Teori:**\n",
        "Mekanisme perhatian merevolusi NLP, terutama NMT, dengan memungkinkan decoder untuk \"fokus\" pada bagian-bagian yang paling relevan dari sekuens input (encoder output) pada setiap langkah waktu. Ini secara efektif memperpendek \"jalur\" dari input ke output yang relevan, mengatasi masalah *short-term memory* pada RNN yang dalam. Model perhatian menghitung skor (atau \"energi\") untuk setiap pasangan output encoder dan keadaan tersembunyi decoder sebelumnya, yang kemudian diubah menjadi bobot probabilitas. Bobot ini digunakan untuk menghitung jumlah terbobot dari output encoder, yang kemudian digunakan oleh decoder. Contoh populer adalah *Bahdanau attention* (juga dikenal sebagai *concatenative attention* atau *additive attention*) dan *Luong attention* (atau *multiplicative attention*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gtp-ttVxcbY2"
      },
      "outputs": [],
      "source": [
        "# Luong Attention (contoh, perlu konteks model Encoder-Decoder yang lengkap)\n",
        "# from tf_agents.seq2seq import LuongAttention # Perhatikan ini adalah tf_agents, bukan tfa.seq2seq\n",
        "# Karena contoh dari buku menggunakan tfa.seq2seq, kita akan merujuk ke sana.\n",
        "\n",
        "# from tf_agents.seq2seq import attention_wrapper # Ini bukan bagian dari tfa.seq2seq di versi terbaru TF-Agents\n",
        "\n",
        "# Fungsionalitas Attention di Keras/TensorFlow telah diintegrasikan ke keras.layers.Attention.\n",
        "\n",
        "# Luong Attention\n",
        "# attention_mechanism = tfa.seq2seq.attention_wrapper.LuongAttention(\n",
        "#     units, encoder_state, memory_sequence_length=encoder_sequence_length) # units adalah dimensi keadaan tersembunyi decoder\n",
        "\n",
        "# attention_decoder_cell = tfa.seq2seq.attention_wrapper.AttentionWrapper(\n",
        "#     decoder_cell, attention_mechanism, attention_layer_size=units) # units adalah dimensi output dari wrapper perhatian\n",
        "\n",
        "# Contoh penggunaan keras.layers.Attention (lebih modern):\n",
        "# query = decoder_state # Misal dari GRU/LSTM decoder\n",
        "# value = encoder_outputs # Misal dari GRU/LSTM encoder (semua langkah waktu)\n",
        "# attention_output = keras.layers.Attention()([query, value])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okWWhcPKcbY2"
      },
      "source": [
        "#### **4.1. Visual Attention**\n",
        "\n",
        "**Teori:**\n",
        "Mekanisme perhatian tidak terbatas pada NLP. *Visual attention* digunakan dalam tugas-tugas seperti generasi *caption* gambar. Dalam konteks ini, model perhatian belajar untuk fokus pada bagian-bagian yang paling relevan dari gambar input (sering kali direpresentasikan oleh *feature maps* dari CNN) saat menghasilkan setiap kata dalam *caption*. Ini membantu model untuk menjelaskan gambar dengan lebih akurat dengan mengasosiasikan kata-kata tertentu dengan area visual tertentu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "J1fACmWGcbY2"
      },
      "outputs": [],
      "source": [
        "# Visual attention biasanya melibatkan output dari CNN (feature maps) sebagai 'value'\n",
        "# dan state dari RNN (yang menghasilkan caption) sebagai 'query'.\n",
        "# keras.layers.Attention dapat digunakan untuk ini.\n",
        "\n",
        "# Contoh konseptual:\n",
        "# cnn_feature_maps = ... # Output dari lapisan CNN\n",
        "# rnn_hidden_state = ... # State tersembunyi dari GRU/LSTM decoder\n",
        "\n",
        "# # Perhatian visual\n",
        "# visual_attention_output = keras.layers.Attention()([rnn_hidden_state, cnn_feature_maps])\n",
        "# # Output ini kemudian akan digabungkan dengan input lain dari RNN decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hu6_IZNcbY2"
      },
      "source": [
        "#### **4.2. Perhatian Adalah Semua yang Anda Butuhkan: Arsitektur Transformer**\n",
        "\n",
        "**Teori:**\n",
        "Makalah *groundbreaking* tahun 2017 \"Attention Is All You Need\" memperkenalkan arsitektur Transformer, yang mencapai *state-of-the-art* dalam NMT tanpa menggunakan lapisan rekuren atau konvolusional. Sebaliknya, Transformer sangat mengandalkan mekanisme perhatian, khususnya \"self-attention\" dan \"multi-head attention\".\n",
        "\n",
        "Komponen utama Transformer meliputi:\n",
        "* **Positional Embeddings**: Karena Transformer tidak memiliki konsep urutan, *positional embeddings* ditambahkan ke *word embeddings* untuk memberikan informasi posisi kata dalam sekuens.\n",
        "* **Multi-Head Attention**: Ini adalah komponen inti yang memungkinkan model untuk secara bersamaan fokus pada berbagai bagian sekuens input (atau sekuens output itu sendiri, dalam kasus *self-attention*) melalui beberapa \"kepala\" perhatian yang berbeda. Setiap kepala belajar untuk melihat hubungan yang berbeda.\n",
        "* **Scaled Dot-Product Attention**: Ini adalah dasar dari *multi-head attention*, yang menghitung skor kesamaan antara *queries* dan *keys*, lalu menggunakannya untuk menimbang *values*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2fbmQEkdcbY2"
      },
      "outputs": [],
      "source": [
        "# Karena arsitektur Transformer cukup kompleks, implementasi lengkapnya akan sangat panjang.\n",
        "# Buku merujuk pada tutorial TensorFlow untuk implementasi lebih lanjut.\n",
        "# Di sini, kita akan menunjukkan komponen kunci secara konseptual.\n",
        "\n",
        "# Positional Encoding (contoh implementasi dari buku)\n",
        "class PositionalEncoding(keras.layers.Layer):\n",
        "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
        "        super().__init__(dtype=dtype, **kwargs)\n",
        "        if max_dims % 2 == 1: max_dims += 1 # max_dims harus genap\n",
        "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
        "        pos_emb = np.empty((1, max_steps, max_dims))\n",
        "        pos_emb[0, :, ::2] = np.sin(p / 10000**(2 * i / max_dims)).T\n",
        "        pos_emb[0, :, 1::2] = np.cos(p / 10000**(2 * i / max_dims)).T\n",
        "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        shape = tf.shape(inputs)\n",
        "        return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]\n",
        "\n",
        "# Contoh penggunaan PositionalEncoding dalam model Transformer:\n",
        "embed_size_transformer = 512\n",
        "max_steps_transformer = 500\n",
        "vocab_size_transformer = 10000\n",
        "\n",
        "encoder_inputs_transformer = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "decoder_inputs_transformer = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "\n",
        "embeddings_transformer = keras.layers.Embedding(vocab_size_transformer, embed_size_transformer)\n",
        "encoder_embeddings_transformer = embeddings_transformer(encoder_inputs_transformer)\n",
        "decoder_embeddings_transformer = embeddings_transformer(decoder_inputs_transformer)\n",
        "\n",
        "positional_encoding_layer = PositionalEncoding(max_steps_transformer, max_dims=embed_size_transformer)\n",
        "encoder_in_transformer = positional_encoding_layer(encoder_embeddings_transformer)\n",
        "decoder_in_transformer = positional_encoding_layer(decoder_embeddings_transformer)\n",
        "\n",
        "# Scaled Dot-Product Attention (konseptual, keras.layers.Attention sudah mengimplementasikan ini)\n",
        "# Z_encoder = keras.layers.Attention(use_scale=True)([encoder_in_transformer, encoder_in_transformer])\n",
        "# Z_decoder_masked = keras.layers.Attention(use_scale=True, causal=True)([decoder_in_transformer, decoder_in_transformer])\n",
        "# Z_decoder_cross_attention = keras.layers.Attention(use_scale=True)([Z_decoder_masked, Z_encoder])\n",
        "\n",
        "# Multi-Head Attention (secara konseptual, ini adalah beberapa lapisan Attention yang berjalan paralel\n",
        "# diikuti dengan Dense layer. Keras 2.x belum punya MultiHeadAttention langsung,\n",
        "# tetapi ada di TF 2.x dengan `tf.keras.layers.MultiHeadAttention`)\n",
        "# Misalnya, jika kita menggunakan tf.keras.layers.MultiHeadAttention:\n",
        "# from tensorflow.keras.layers import MultiHeadAttention\n",
        "# multi_head_attention_layer = MultiHeadAttention(num_heads=8, key_dim=embed_size_transformer//8)\n",
        "# attention_output = multi_head_attention_layer(query=encoder_in_transformer,\n",
        "#                                                 value=encoder_in_transformer,\n",
        "#                                                 key=encoder_in_transformer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2WIzQY_cbY3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQwb91fAcbY3"
      },
      "source": [
        "### **5. Inovasi Terbaru dalam Model Bahasa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muE3o_GhcbY3"
      },
      "source": [
        "#### **Teori:**\n",
        "Tahun 2018 dan 2019 menyaksikan kemajuan luar biasa dalam NLP, sering disebut sebagai \"momen ImageNet untuk NLP\".  Inovasi-inovasi ini sebagian besar berpusat pada:\n",
        "* **Tokenisasi Subkata yang Lebih Baik**: Teknik seperti Byte-Pair Encoding (BPE) dan WordPiece memungkinkan tokenisasi yang independen dari bahasa, menangani kata-kata yang jarang dan bahkan kata-kata yang belum pernah terlihat sebelumnya dengan memecahnya menjadi unit subkata.\n",
        "* **Pergeseran dari LSTM ke Transformer**: Arsitektur Transformer, dengan mekanisme perhatiannya, terbukti lebih efisien dan efektif untuk tugas-tugas bahasa dibandingkan RNN berbasis LSTM tradisional, terutama untuk sekuens panjang.\n",
        "* **Pelatihan Awal Model Bahasa Universal (Self-Supervised Learning)**: Model-model besar dilatih pada korpus teks yang sangat besar menggunakan tugas-tugas *self-supervised* (misalnya, memprediksi kata yang hilang atau sekuens kalimat berikutnya). Ini memungkinkan model untuk belajar representasi bahasa yang kaya tanpa memerlukan label manusia. Model-model ini kemudian dapat di-*fine-tune* pada berbagai tugas hilir dengan data berlabel yang jauh lebih sedikit, sebuah teknik yang dikenal sebagai *transfer learning* atau *zero-shot learning*. Contoh model ini adalah ELMo, ULMFiT, GPT (GPT-2), dan BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNM647GIcbY7",
        "outputId": "cfc06bfb-afa8-4421-f3f7-17f6533bf487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model-model seperti BERT dan GPT-2 sangat besar dan seringkali membutuhkan sumber daya komputasi yang signifikan.\n",
            "Anda dapat menjelajahi implementasinya di:\n",
            "- TensorFlow Model Garden: https://github.com/tensorflow/models/tree/master/official/nlp\n",
            "- Hugging Face Transformers: https://huggingface.co/transformers/\n"
          ]
        }
      ],
      "source": [
        "# Karena ini adalah bagian teoritis yang membahas perkembangan terbaru, tidak ada kode implementasi langsung yang akan diberikan.\n",
        "# Namun, Anda bisa menambahkan catatan atau tautan ke implementasi model-model seperti BERT atau GPT-2\n",
        "# yang tersedia di TensorFlow Model Garden atau Hugging Face Transformers.\n",
        "\n",
        "# Contoh:\n",
        "print(\"Model-model seperti BERT dan GPT-2 sangat besar dan seringkali membutuhkan sumber daya komputasi yang signifikan.\")\n",
        "print(\"Anda dapat menjelajahi implementasinya di:\")\n",
        "print(\"- TensorFlow Model Garden: https://github.com/tensorflow/models/tree/master/official/nlp\")\n",
        "print(\"- Hugging Face Transformers: https://huggingface.co/transformers/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0r_aoHEcbY8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYYWtizncbY8"
      },
      "source": [
        "### **Latihan**\n",
        "\n",
        "Latihan-latihan ini akan membantu Anda memperdalam pemahaman dan keterampilan praktis dalam mengimplementasikan konsep inti Machine Learning melalui reproduksi kode dan penjelasan teoritis yang terstruktur, menggunakan buku Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems (O’Reilly) sebagai referensi utama.\n",
        "\n",
        "1.  **RNN Stateful vs. Stateless:**\n",
        "    * Jelaskan kelebihan dan kekurangan menggunakan RNN stateful dibandingkan RNN stateless.\n",
        "2.  **Encoder-Decoder untuk Terjemahan Otomatis:**\n",
        "    * Mengapa orang menggunakan RNN Encoder-Decoder daripada RNN sekuens-ke-sekuens biasa untuk terjemahan otomatis?\n",
        "3.  **Sekuens Panjang Bervariasi:**\n",
        "    * Bagaimana Anda bisa menangani sekuens input dengan panjang yang bervariasi? Bagaimana dengan sekuens output dengan panjang yang bervariasi?\n",
        "4.  **Beam Search:**\n",
        "    * Apa itu *beam search* dan mengapa Anda menggunakannya? Alat apa yang dapat Anda gunakan untuk mengimplementasikannya?\n",
        "5.  **Mekanisme Perhatian:**\n",
        "    * Apa itu mekanisme perhatian? Bagaimana cara kerjanya dan bagaimana mekanisme perhatian membantu dalam tugas-tugas NLP?\n",
        "6.  **Lapisan Paling Penting di Transformer:**\n",
        "    * Apa lapisan terpenting dalam arsitektur Transformer? Apa tujuannya?\n",
        "7.  **Sampled Softmax:**\n",
        "    * Kapan Anda perlu menggunakan *sampled softmax*?\n",
        "8.  **Embedded Reber Grammars (Lanjutan dari Chapter 15):**\n",
        "    * Gunakan *embedded Reber grammars* yang digunakan oleh Hochreiter dan Schmidhuber. Pilih tata bahasa Reber tertanam tertentu, lalu latih RNN untuk mengidentifikasi apakah sebuah string mematuhi tata bahasa tersebut atau tidak. Anda harus terlebih dahulu menulis fungsi yang mampu menghasilkan *batch* pelatihan yang berisi sekitar 50% string yang mematuhi tata bahasa, dan 50% yang tidak.\n",
        "9.  **Terjemahan Tanggal:**\n",
        "    * Latih model Encoder-Decoder yang dapat mengonversi string tanggal dari satu format ke format lain (misalnya, dari “April 22, 2019” menjadi “2019-04-22”).\n",
        "10. **Neural Machine Translation with Attention Tutorial:**\n",
        "    * Ikuti tutorial Neural Machine Translation with Attention dari TensorFlow.\n",
        "11. **Teks Shakespeare yang Lebih Meyakinkan:**\n",
        "    * Gunakan salah satu model bahasa terbaru (misalnya, BERT) untuk menghasilkan teks Shakespeare yang lebih meyakinkan.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytLCxNEncbY8"
      },
      "source": [
        "**Catatan Penting:**\n",
        "\n",
        "* **Pelatihan Model:** Bagian kode `model.fit()` untuk pelatihan dikomentari. Anda perlu meng-uncomment-nya untuk melatih model. Pelatihan mungkin memerlukan waktu yang signifikan, terutama untuk model yang lebih besar.\n",
        "* **Sumber Daya:** Melatih model NLP yang kompleks, terutama Transformer dan model bahasa besar, membutuhkan sumber daya komputasi yang substansial (GPU). Anda mungkin perlu menggunakan layanan seperti Google Colab (dengan GPU Runtime gratis) atau platform cloud lainnya.\n",
        "* **Versi Library:** TensorFlow dan Keras terus berkembang. Jika Anda mengalami masalah kompatibilitas, periksa kembali dokumentasi resmi TensorFlow dan versi *notebook* yang diperbarui di repositori GitHub buku ini.\n",
        "* **Data Nyata untuk NMT:** Contoh NMT di atas bersifat konseptual dan menggunakan *dummy vocabulary*. Untuk melatih model NMT nyata, Anda perlu dataset paralel (misalnya, pasangan kalimat Inggris-Prancis) dan melakukan pra-pemrosesan yang lebih canggih (seperti tokenisasi subkata dan pembuatan kosakata)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}