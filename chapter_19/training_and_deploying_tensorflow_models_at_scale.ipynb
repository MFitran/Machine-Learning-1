{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJiQhbaathyU"
      },
      "source": [
        "# Bab 19: Training and Deploying TensorFlow Models at Scale\n",
        "\n",
        "Bab ini akan membahas bagaimana melatih dan menerapkan model TensorFlow dalam skala besar. Kita akan belajar tentang deployment model ke TF Serving dan Google Cloud AI Platform, serta membahas penggunaan GPU dan strategi distribusi untuk mempercepat pelatihan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Y-TD-2thyZ"
      },
      "source": [
        "## 1. Menyajikan Model TensorFlow (Serving a TensorFlow Model)\n",
        "\n",
        "Setelah model TensorFlow dilatih, langkah selanjutnya adalah menerapkannya ke dalam produksi. Meskipun model dapat digunakan langsung dalam kode Python, seiring bertambahnya infrastruktur, lebih baik untuk membungkus model dalam layanan khusus yang hanya berfungsi untuk membuat prediksi. Hal ini akan memisahkan model dari sisa infrastruktur, memudahkan pembaruan versi model, scaling layanan, melakukan eksperimen A/B, dan memastikan semua komponen perangkat lunak mengandalkan versi model yang sama.\n",
        "\n",
        "**TF Serving** adalah server model yang sangat efisien dan teruji, ditulis dalam C++. Ini dapat menangani beban tinggi, menyajikan berbagai versi model, dan secara otomatis menerapkan versi terbaru dari repositori model.\n",
        "\n",
        "### 1.1 Mengekspor SavedModels\n",
        "\n",
        "TensorFlow menyediakan fungsi `tf.saved_model.save()` untuk mengekspor model ke format **SavedModel**. Format ini menyimpan grafik komputasi model dan bobotnya. Ini juga dapat mencakup lapisan pra-pemrosesan sehingga model dapat langsung menerima data mentah di produksi.\n",
        "\n",
        "Sebuah SavedModel mewakili versi model dan disimpan sebagai direktori yang berisi file `saved_model.pb` (mendefinisikan grafik komputasi sebagai protokol buffer serial) dan subdirektori `variables` (berisi nilai variabel). SavedModel juga dapat menyertakan subdirektori `assets` untuk data tambahan seperti file kosakata.\n",
        "\n",
        "**SavedModel hanya dapat digunakan dengan model yang didasarkan secara eksklusif pada operasi TensorFlow**, mengecualikan `tf.py_function()` (yang membungkus kode Python arbitrer) dan model `tf.keras` dinamis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3F7SlRuthya",
        "outputId": "d885f168-e513-4e47-91af-f22110e7ad7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-serving-api in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-serving-api) (1.73.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-serving-api) (5.29.5)\n",
            "Requirement already satisfied: tensorflow<3,>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-serving-api) (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (1.17.2)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.19.0->tensorflow-serving-api) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<3,>=2.19.0->tensorflow-serving-api) (0.1.2)\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4555 - loss: 1.7754\n",
            "Epoch 2/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6917 - loss: 0.9411\n",
            "Epoch 3/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7342 - loss: 0.7928\n",
            "Epoch 4/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.6999\n",
            "Epoch 5/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.6252\n",
            "Model disimpan di: my_mnist_model/0001\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import grpc\n",
        "!pip install tensorflow-serving-api\n",
        "from tensorflow_serving.apis import predict_pb2\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "# Memuat dan menyiapkan data MNIST (seperti di Bab 10)\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_new = X_test[:3] # Contoh instance baru\n",
        "\n",
        "# Membangun dan melatih model sederhana (seperti di Bab 10)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Gunakan subset kecil untuk pelatihan agar lebih cepat\n",
        "history = model.fit(X_train_full[:5000], y_train_full[:5000], epochs=5)\n",
        "\n",
        "# Mengekspor model ke format SavedModel\n",
        "model_version = \"0001\"\n",
        "model_name = \"my_mnist_model\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "tf.saved_model.save(model, model_path)\n",
        "\n",
        "print(f\"Model disimpan di: {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCcb08vJthyb"
      },
      "source": [
        "### 1.2 Menginstal TensorFlow Serving\n",
        "\n",
        "Ada berbagai cara untuk menginstal TF Serving, termasuk menggunakan citra Docker. Menggunakan Docker sangat direkomendasikan karena mudah diinstal, tidak mengganggu sistem Anda, dan menawarkan kinerja tinggi.\n",
        "\n",
        "**Langkah-langkah Instalasi TF Serving dengan Docker:**\n",
        "1. **Instal Docker**: Pastikan Docker terinstal di sistem Anda.\n",
        "2. **Pull Image TF Serving**: Unduh citra Docker resmi TF Serving:\n",
        "   ```bash\n",
        "   docker pull tensorflow/serving\n",
        "   ```\n",
        "3. **Jalankan Container TF Serving**: Jalankan perintah berikut dari direktori root proyek Anda (di mana model disimpan):\n",
        "   ```bash\n",
        "   docker run -it --rm -p 8500:8500 -p 8501:8501 \\\n",
        "     -v \"$(pwd)/my_mnist_model:/models/my_mnist_model\" \\\n",
        "     -e MODEL_NAME=my_mnist_model \\\n",
        "     tensorflow/serving\n",
        "   ```\n",
        "   - `-it`: Membuat container interaktif dan menampilkan output server.\n",
        "   - `--rm`: Menghapus container saat dihentikan (untuk menghindari kekacauan).\n",
        "   - `-p 8500:8500`: Meneruskan port TCP 8500 host ke port 8500 container (untuk gRPC API).\n",
        "   - `-p 8501:8501`: Meneruskan port TCP 8501 host ke port 8501 container (untuk REST API).\n",
        "   - `-v \"$(pwd)/my_mnist_model:/models/my_mnist_model\"`: Membuat direktori model di host tersedia di dalam container. Sesuaikan path jika berbeda.\n",
        "   - `-e MODEL_NAME=my_mnist_model`: Mengatur variabel lingkungan `MODEL_NAME` di container, sehingga TF Serving tahu model mana yang akan disajikan. Secara default, ia akan mencari model di direktori `/models` dan secara otomatis menyajikan versi terbaru yang ditemukan.\n",
        "\n",
        "Output dari perintah ini akan menunjukkan bahwa TF Serving telah berjalan dan memuat model Anda.\n",
        "\n",
        "### 1.3 Melakukan Query TF Serving melalui REST API\n",
        "\n",
        "REST API cocok untuk data input dan output yang tidak terlalu besar. Format JSON yang digunakan berbasis teks, yang efisien tetapi kurang efisien dibandingkan format biner untuk transfer data besar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuFdl-LIthyc",
        "outputId": "65b0de6a-3f13-4dce-ad05-1c701370b823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error koneksi ke TF Serving (REST): HTTPConnectionPool(host='localhost', port=8501): Max retries exceeded with url: /v1/models/my_mnist_model:predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a72eadc2c90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "Pastikan TF Serving container berjalan dengan benar.\n"
          ]
        }
      ],
      "source": [
        "SERVER_URL_REST = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
        "\n",
        "input_data_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist()\n",
        "})\n",
        "\n",
        "try:\n",
        "    response_rest = requests.post(SERVER_URL_REST, data=input_data_json)\n",
        "    response_rest.raise_for_status() # Menimbulkan exception jika ada error HTTP\n",
        "    response_rest = response_rest.json()\n",
        "    y_proba_rest = np.array(response_rest[\"predictions\"])\n",
        "    print(\"Prediksi dari REST API:\")\n",
        "    print(y_proba_rest.round(2))\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"Error koneksi ke TF Serving (REST): {e}\")\n",
        "    print(\"Pastikan TF Serving container berjalan dengan benar.\")\n",
        "except Exception as e:\n",
        "    print(f\"Terjadi kesalahan: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOJ3ksQLthyc"
      },
      "source": [
        "### 1.4 Melakukan Query TF Serving melalui gRPC API\n",
        "\n",
        "gRPC API lebih efisien untuk transfer data besar karena menggunakan format biner kompak dan protokol komunikasi efisien berbasis HTTP/2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB6xovF5thyd",
        "outputId": "135abb36-f113-47a0-806c-be01e7bf9638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Terjadi kesalahan: 'Sequential' object has no attribute 'input_names'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Impor di sini agar tidak mengganggu jika tidak terinstal\n",
        "    from tensorflow_serving.apis import predict_pb2\n",
        "    from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "    channel = grpc.insecure_channel('localhost:8500')\n",
        "    predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "\n",
        "    request_grpc = predict_pb2.PredictRequest()\n",
        "    request_grpc.model_spec.name = model_name\n",
        "    request_grpc.model_spec.signature_name = \"serving_default\"\n",
        "\n",
        "    # Mendapatkan nama input dari model Keras\n",
        "    input_name_grpc = model.input_names[0]\n",
        "    request_grpc.inputs[input_name_grpc].CopyFrom(\n",
        "        tf.make_tensor_proto(X_new, dtype=tf.float32))\n",
        "\n",
        "    response_grpc = predict_service.Predict(request_grpc, timeout=10.0)\n",
        "\n",
        "    output_name_grpc = model.output_names[0]\n",
        "    outputs_proto_grpc = response_grpc.outputs[output_name_grpc]\n",
        "    y_proba_grpc = tf.make_ndarray(outputs_proto_grpc)\n",
        "\n",
        "    print(\"\\nPrediksi dari gRPC API:\")\n",
        "    print(y_proba_grpc.round(2))\n",
        "\n",
        "except ImportError:\n",
        "    print(\"\\n tensorflow-serving-api atau grpcio tidak terinstal. Lewati pengujian gRPC.\")\n",
        "except grpc.RpcError as e:\n",
        "    print(f\"\\nError gRPC ke TF Serving: {e}\")\n",
        "    print(\"Pastikan TF Serving container berjalan dengan benar dan gRPC port (8500) terbuka.\")\n",
        "except Exception as e:\n",
        "    print(f\"Terjadi kesalahan: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wePXCs1Gthye"
      },
      "source": [
        "### 1.5 Menerapkan Versi Model Baru\n",
        "\n",
        "Secara berkala, TF Serving memeriksa versi model baru. Jika ditemukan, ia akan menangani transisi dengan baik: permintaan yang tertunda akan dijawab dengan versi model sebelumnya, sementara permintaan baru akan ditangani dengan versi baru. Setelah semua permintaan tertunda selesai, versi model sebelumnya akan dilepaskan.\n",
        "\n",
        "Untuk menerapkan versi baru, cukup ekspor SavedModel ke subdirektori dengan nomor versi yang lebih tinggi.\n",
        "\n",
        "```python\n",
        "# Melatih model versi baru\n",
        "model_new_version = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"tanh\"), # Mengubah fungsi aktivasi untuk demonstrasi\n",
        "    keras.layers.Dense(100, activation=\"tanh\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model_new_version.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                           optimizer=\"adam\", # Mengubah optimizer\n",
        "                           metrics=[\"accuracy\"])\n",
        "history_new = model_new_version.fit(X_train_full[:5000], y_train_full[:5000], epochs=5)\n",
        "\n",
        "model_version_new = \"0002\" # Versi baru\n",
        "model_path_new = os.path.join(model_name, model_version_new)\n",
        "tf.saved_model.save(model_new_version, model_path_new)\n",
        "\n",
        "print(f\"Model versi baru disimpan di: {model_path_new}\")\n",
        "print(\"TF Serving akan secara otomatis memuat versi baru ini setelah beberapa saat.\")\n",
        "```\n",
        "\n",
        "Secara default, TF Serving dapat mengaktifkan **batching otomatis** untuk permintaan yang diterima dalam waktu singkat, yang dapat meningkatkan kinerja secara signifikan dengan memanfaatkan kekuatan GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HBGMA6Hthye",
        "outputId": "eef797cc-172e-47c9-9a6a-6648c16f4fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.6502 - loss: 0.9928\n",
            "Epoch 2/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8202 - loss: 0.4854\n",
            "Epoch 3/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8576 - loss: 0.3855\n",
            "Epoch 4/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8572 - loss: 0.3983\n",
            "Epoch 5/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8686 - loss: 0.3616\n",
            "Model versi baru disimpan di: my_mnist_model/0002\n",
            "TF Serving akan secara otomatis memuat versi baru ini setelah beberapa saat.\n"
          ]
        }
      ],
      "source": [
        "# Melatih model versi baru\n",
        "model_new_version = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"tanh\"), # Mengubah fungsi aktivasi untuk demonstrasi\n",
        "    keras.layers.Dense(100, activation=\"tanh\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model_new_version.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                           optimizer=\"adam\", # Mengubah optimizer\n",
        "                           metrics=[\"accuracy\"])\n",
        "history_new = model_new_version.fit(X_train_full[:5000], y_train_full[:5000], epochs=5)\n",
        "\n",
        "model_version_new = \"0002\" # Versi baru\n",
        "model_path_new = os.path.join(model_name, model_version_new)\n",
        "tf.saved_model.save(model_new_version, model_path_new)\n",
        "\n",
        "print(f\"Model versi baru disimpan di: {model_path_new}\")\n",
        "print(\"TF Serving akan secara otomatis memuat versi baru ini setelah beberapa saat.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REoroIh-thyf"
      },
      "source": [
        "## 2. Menerapkan Model ke Google Cloud AI Platform\n",
        "\n",
        "**Google Cloud AI Platform** (sebelumnya dikenal sebagai Google Cloud ML Engine) adalah layanan cloud yang mengelola penyediaan dan konfigurasi VM GPU untuk pelatihan dan penerapan model TensorFlow.\n",
        "\n",
        "### 2.1 Membuat Layanan Prediksi di GCP AI Platform\n",
        "\n",
        "Langkah-langkah awal melibatkan pengaturan akun GCP, mengaktifkan API yang diperlukan (Storage API, AI Platform API), membuat bucket di Google Cloud Storage (GCS) untuk menyimpan model dan data, dan mengunggah model SavedModel ke GCS.\n",
        "\n",
        "Setelah itu, model dan versi model perlu dikonfigurasi di AI Platform. Ini melibatkan penentuan nama model, versi, versi TensorFlow dan runtime, jenis mesin, dan jalur model di GCS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ej7QkTQnthyg"
      },
      "outputs": [],
      "source": [
        " # Langkah-langkah ini dijalankan di Google Cloud Shell atau lingkungan dengan gcloud SDK terinstal\n",
        "\n",
        " # Pastikan Anda sudah login ke GCP dan memilih proyek yang benar\n",
        " # gcloud auth login\n",
        " # gcloud config set project your-gcp-project-id\n",
        "\n",
        " # 1. Buat bucket GCS (ganti 'your-unique-bucket-name' dengan nama bucket unik Anda)\n",
        " # gsutil mb gs://your-unique-bucket-name\n",
        "\n",
        " # 2. Unggah model SavedModel Anda ke GCS\n",
        " # gsutil cp -r my_mnist_model/ gs://your-unique-bucket-name/models/\n",
        "\n",
        " # 3. Buat model di AI Platform\n",
        " # gcloud ai-platform models create my_mnist_model \\\n",
        " #    --regions global # Atau region spesifik seperti us-central1\n",
        "\n",
        " # 4. Buat versi model\n",
        " # gcloud ai-platform versions create v0001 \\\n",
        " #    --model my_mnist_model \\\n",
        " #    --origin gs://your-unique-bucket-name/models/my_mnist_model/0001/ \\\n",
        " #    --runtime-version 2.11 \\\n",
        " #    --framework TENSORFLOW \\\n",
        " #    --python-version 3.9 \\\n",
        " #    --machine-type n1-standard-4 # Contoh: Ubah sesuai kebutuhan dan kuota Anda\n",
        "\n",
        " # Catatan: Runtime version 2.11 dan Python version 3.9 adalah contoh versi terbaru saat ini.\n",
        " # Selalu periksa dokumentasi Google Cloud untuk versi yang didukung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDg8d4Vethyg"
      },
      "source": [
        "### 2.2 Menggunakan Layanan Prediksi\n",
        "\n",
        "AI Platform menangani enkripsi dan autentikasi melalui SSL/TLS dan token. Direkomendasikan untuk menggunakan **service account** dengan hak akses terbatas untuk aplikasi klien Anda.\n",
        "\n",
        "Untuk melakukan query layanan prediksi, Anda dapat menggunakan Google API Client Library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ec0wnRdnthyg"
      },
      "outputs": [],
      "source": [
        "# Contoh kode untuk menggunakan layanan prediksi (ini memerlukan service account key file)\n",
        "# Pastikan Anda telah mengunduh file JSON kunci service account Anda dan menempatkannya di direktori yang benar.\n",
        "\n",
        "# import os\n",
        "# import googleapiclient.discovery\n",
        "\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"path/to/your/service_account_key.json\"\n",
        "\n",
        "# project_id = \"your-gcp-project-id\" # Ganti dengan ID proyek GCP Anda\n",
        "# model_id = \"my_mnist_model\"\n",
        "# model_path_gcp = f\"projects/{project_id}/models/{model_id}\"\n",
        "\n",
        "# ml_resource = googleapiclient.discovery.build(\"ml\", \"v1\").projects()\n",
        "\n",
        "# def predict_gcp(X_data):\n",
        "#     input_data_json_gcp = {\"signature_name\": \"serving_default\",\n",
        "#                            \"instances\": X_data.tolist()}\n",
        "#     request_gcp = ml_resource.predict(name=model_path_gcp, body=input_data_json_gcp)\n",
        "#     response_gcp = request_gcp.execute()\n",
        "#     if \"error\" in response_gcp:\n",
        "#         raise RuntimeError(response_gcp[\"error\"])\n",
        "#     return np.array([pred[model.output_names[0]] for pred in response_gcp[\"predictions\"]])\n",
        "\n",
        "# try:\n",
        "#     y_proba_gcp = predict_gcp(X_new)\n",
        "#     print(\"\\nPrediksi dari GCP AI Platform:\")\n",
        "#     print(y_proba_gcp.round(2))\n",
        "# except Exception as e:\n",
        "#     print(f\"\\nError saat memanggil GCP AI Platform: {e}\")\n",
        "#     print(\"Pastikan Anda telah mengaktifkan API, membuat model dan versi, dan kunci service account sudah benar.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dDuqM7pthyg"
      },
      "source": [
        "## 3. Menerapkan Model ke Perangkat Seluler atau Embedded\n",
        "\n",
        "Untuk menerapkan model ke perangkat seluler atau embedded, model harus ringan dan efisien. **TFLite** adalah pustaka yang menyediakan alat untuk mengurangi ukuran model, mengurangi komputasi yang dibutuhkan, dan menyesuaikan model dengan kendala perangkat.\n",
        "\n",
        "### 3.1 Mengurangi Ukuran Model\n",
        "\n",
        "Konverter TFLite dapat mengambil SavedModel dan mengkompresnya ke format yang lebih ringan berdasarkan **FlatBuffers**. Ini adalah pustaka serialisasi lintas platform yang efisien yang dirancang untuk memuat langsung ke RAM tanpa pra-pemrosesan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrA9e646thyh",
        "outputId": "25956982-9990-4586-febf-1e79aeeef785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model berhasil dikonversi ke TFLite: converted_model.tflite\n"
          ]
        }
      ],
      "source": [
        "# Mengonversi SavedModel ke format TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(model_path) # Menggunakan model_path dari versi 0001\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"converted_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "print(\"Model berhasil dikonversi ke TFLite: converted_model.tflite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcMvo-Pdthyh"
      },
      "source": [
        "### 3.2 Kuantisasi (Quantization)\n",
        "\n",
        "Kuantisasi adalah teknik untuk mengurangi ukuran model lebih lanjut dengan mengonversi bobot model ke bilangan bulat 8-bit, yang dapat mengurangi ukuran model hingga empat kali lipat dibandingkan float 32-bit.\n",
        "\n",
        "**Post-training quantization**: Kuantisasi bobot setelah pelatihan selesai. Ini adalah pendekatan paling sederhana dan paling umum.\n",
        "**Quantization-aware training**: Menambahkan operasi kuantisasi palsu ke model selama pelatihan agar model belajar untuk mengabaikan noise kuantisasi, sehingga bobot akhir lebih kuat terhadap kuantisasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skHTnwqethyh",
        "outputId": "d6c5a4bc-f9d1-4f6d-cc61-2288eb554563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model berhasil dikonversi dan dikuantisasi ke TFLite: converted_model_quant.tflite\n"
          ]
        }
      ],
      "source": [
        "# Contoh post-training quantization\n",
        "converter_quant = tf.lite.TFLiteConverter.from_saved_model(model_path)\n",
        "converter_quant.optimizations = [tf.lite.Optimize.DEFAULT] # Ini mencakup kuantisasi bobot default\n",
        "tflite_model_quant = converter_quant.convert()\n",
        "\n",
        "with open(\"converted_model_quant.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model_quant)\n",
        "print(\"Model berhasil dikonversi dan dikuantisasi ke TFLite: converted_model_quant.tflite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_zhqwTPthyh"
      },
      "source": [
        "## 4. Menggunakan GPU untuk Mempercepat Komputasi\n",
        "\n",
        "Melatih jaringan saraf besar pada satu mesin dengan satu CPU dapat memakan waktu berhari-hari atau bahkan berminggu-minggu. Penggunaan **GPU (Graphics Processing Unit)** dapat mempercepat pelatihan secara signifikan, dari hari menjadi menit atau jam.\n",
        "\n",
        "### 4.1 Mengelola RAM GPU\n",
        "\n",
        "Secara default, TensorFlow secara otomatis mengambil semua RAM di semua GPU yang tersedia saat pertama kali komputasi dijalankan. Ini dilakukan untuk membatasi fragmentasi RAM GPU.\n",
        "\n",
        "Beberapa cara untuk mengelola RAM GPU:\n",
        "1. **Menetapkan GPU ke Proses Tunggal**: Mengatur variabel lingkungan `CUDA_VISIBLE_DEVICES` agar setiap proses hanya melihat kartu GPU tertentu.\n",
        "2. **Membatasi Jumlah RAM**: Memberi tahu TensorFlow untuk hanya mengambil sejumlah RAM GPU tertentu.\n",
        "3. **Pertumbuhan Memori (Memory Growth)**: Memberi tahu TensorFlow untuk mengambil memori hanya saat dibutuhkan (tidak akan pernah melepaskan memori yang sudah diambil).\n",
        "4. **Virtual GPU**: Membagi satu GPU fisik menjadi dua atau lebih GPU virtual (atau logis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaTN0FoJthyh",
        "outputId": "cd9f850a-ceda-4f1c-bd4a-74b56899d8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tidak ada GPU fisik yang ditemukan.\n"
          ]
        }
      ],
      "source": [
        "# Mengelola pertumbuhan memori GPU (harus dijalankan di awal program)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Memberi tahu TensorFlow untuk hanya mengalokasikan memori sesuai kebutuhan\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Pertumbuhan memori harus diatur sebelum GPU diinisialisasi\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"Tidak ada GPU fisik yang ditemukan.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eto-I8cthyi"
      },
      "source": [
        "### 4.2 Menempatkan Operasi dan Variabel di Perangkat\n",
        "\n",
        "Secara default, semua variabel dan operasi akan ditempatkan di GPU pertama (`/gpu:0`), kecuali untuk operasi dan variabel yang tidak memiliki kernel GPU (akan ditempatkan di CPU: `/cpu:0`).\n",
        "\n",
        "Kita dapat secara manual menempatkan operasi dan variabel pada perangkat tertentu menggunakan konteks `tf.device()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr2iY34Lthyi",
        "outputId": "74a772ed-2b2c-45ef-fdfe-a2b937d9e822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variabel 'a' ditempatkan di: /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Variabel 'b' ditempatkan di: /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Variabel 'c' (dipaksa ke CPU) ditempatkan di: /job:localhost/replica:0/task:0/device:CPU:0\n"
          ]
        }
      ],
      "source": [
        "a = tf.Variable(42.0)\n",
        "print(f\"Variabel 'a' ditempatkan di: {a.device}\")\n",
        "\n",
        "b = tf.Variable(42) # Integer variables often default to CPU\n",
        "print(f\"Variabel 'b' ditempatkan di: {b.device}\")\n",
        "\n",
        "with tf.device(\"/cpu:0\"):\n",
        "    c = tf.Variable(42.0)\n",
        "print(f\"Variabel 'c' (dipaksa ke CPU) ditempatkan di: {c.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrwB_xYZthyi"
      },
      "source": [
        "### 4.3 Eksekusi Paralel di Beberapa Perangkat\n",
        "\n",
        "TensorFlow mengeksekusi operasi dalam grafik komputasi secara paralel saat memungkinkan. Ketika `tf.function` dijalankan, ia menganalisis grafiknya untuk menemukan operasi yang perlu dievaluasi dan menjalankan operasi dengan dependensi nol (operasi sumber) di antrean evaluasi perangkat masing-masing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE5CY92Ethyi"
      },
      "source": [
        "## 5. Melatih Model dalam Skala Besar Menggunakan Distribution Strategies API\n",
        "\n",
        "TensorFlow menyediakan **Distribution Strategies API** yang menyederhanakan pelatihan model dalam skala besar, baik di beberapa GPU pada satu mesin maupun di beberapa server.\n",
        "\n",
        "### 5.1 Paralelisme Data (Data Parallelism)\n",
        "\n",
        "Paralelisme data adalah pendekatan di mana model direplikasi di setiap perangkat, dan setiap langkah pelatihan dijalankan secara bersamaan di semua replika, menggunakan mini-batch yang berbeda untuk setiap replika. Gradien yang dihitung oleh setiap replika kemudian dirata-ratakan dan hasilnya digunakan untuk memperbarui parameter model.\n",
        "\n",
        "Dua pendekatan utama:\n",
        "1. **Strategi Mirrored (Mirrored Strategy)**: Mencerminkan semua parameter model di semua GPU dan selalu menerapkan pembaruan parameter yang sama persis di setiap GPU. Ini sangat efisien, terutama pada satu mesin, menggunakan algoritma AllReduce.\n",
        "2. **Strategi dengan Parameter Terpusat (Centralized Parameters)**: Menyimpan parameter model di luar perangkat GPU (worker), misalnya di CPU atau server parameter. Ini dapat menggunakan pembaruan sinkron atau asinkron.\n",
        "\n",
        "**Pembaruan Sinkron (Synchronous Updates)**: Agregator menunggu semua gradien tersedia sebelum menghitung rata-rata gradien dan meneruskannya ke optimizer.\n",
        "**Pembaruan Asinkron (Asynchronous Updates)**: Setiap replika memperbarui parameter model segera setelah selesai menghitung gradien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEyUp5G8thyj",
        "outputId": "827bbdf9-4978-4651-f6ce-486bd83eb3f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Menggunakan MirroredStrategy ---\n",
            "Jumlah perangkat yang terdeteksi oleh MirroredStrategy: 1\n",
            "Batch size untuk MirroredStrategy: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.1421 - loss: 2.2973 \n",
            "Epoch 2/2\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2765 - loss: 2.1754\n",
            "Pelatihan dengan MirroredStrategy selesai.\n"
          ]
        }
      ],
      "source": [
        "# Contoh MirroredStrategy (untuk banyak GPU di satu mesin)\n",
        "# Jika Anda tidak memiliki GPU, ini akan menggunakan CPU dan mungkin tidak menunjukkan manfaat paralelisme.\n",
        "print(\"\\n--- Menggunakan MirroredStrategy ---\")\n",
        "try:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(f\"Jumlah perangkat yang terdeteksi oleh MirroredStrategy: {strategy.num_replicas_in_sync}\")\n",
        "\n",
        "    with strategy.scope():\n",
        "        mirrored_model = keras.models.Sequential([\n",
        "            keras.layers.Flatten(input_shape=[28, 28]),\n",
        "            keras.layers.Dense(300, activation=\"relu\"),\n",
        "            keras.layers.Dense(100, activation=\"relu\"),\n",
        "            keras.layers.Dense(10, activation=\"softmax\")\n",
        "        ])\n",
        "        mirrored_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                               optimizer=\"sgd\",\n",
        "                               metrics=[\"accuracy\"])\n",
        "\n",
        "    # Batch size harus dapat dibagi dengan jumlah replika\n",
        "    batch_size_mirrored = 100 * strategy.num_replicas_in_sync\n",
        "    print(f\"Batch size untuk MirroredStrategy: {batch_size_mirrored}\")\n",
        "    history_mirrored = mirrored_model.fit(\n",
        "        X_train_full[:batch_size_mirrored*5], y_train_full[:batch_size_mirrored*5],\n",
        "        epochs=2, batch_size=batch_size_mirrored)\n",
        "    print(\"Pelatihan dengan MirroredStrategy selesai.\")\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"Error saat menginisialisasi MirroredStrategy: {e}\")\n",
        "    print(\"Pastikan Anda memiliki setidaknya satu GPU yang tersedia atau sesuaikan konfigurasi GPU Anda.\")\n",
        "except Exception as e:\n",
        "    print(f\"Terjadi kesalahan lain: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AwkOINSthyj"
      },
      "source": [
        "### 5.2 Paralelisme Model (Model Parallelism)\n",
        "\n",
        "Paralelisme model adalah pendekatan di mana model dipecah menjadi beberapa bagian dan setiap bagian dijalankan pada perangkat yang berbeda. Ini lebih rumit daripada paralelisme data dan keuntungan kinerja sangat bergantung pada arsitektur jaringan saraf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2CHHwkkthyj"
      },
      "source": [
        "## 6. Menjalankan Pekerjaan Pelatihan Besar di Google Cloud AI Platform\n",
        "\n",
        "Untuk pekerjaan pelatihan skala besar, Google Cloud AI Platform dapat mengelola penyediaan dan konfigurasi VM GPU sesuai permintaan Anda. Anda menggunakan alat baris perintah `gcloud` untuk mengirimkan pekerjaan pelatihan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0ts87ZEOthyj"
      },
      "outputs": [],
      "source": [
        "# Contoh perintah untuk mengirimkan pekerjaan pelatihan ke AI Platform\n",
        "# (Ini adalah perintah bash, tidak dijalankan di Jupyter secara langsung)\n",
        "\n",
        "# gcloud ai-platform jobs submit training my_training_job_$(date +%Y%m%d_%H%M%S) \\\n",
        "#    --region us-central1 \\\n",
        "#    --scale-tier BASIC_GPU \\\n",
        "#    --runtime-version 2.11 \\\n",
        "#    --python-version 3.9 \\\n",
        "#    --package-path ./trainer \\\n",
        "#    --module-name trainer.task \\\n",
        "#    --staging-bucket gs://your-unique-bucket-name/staging \\\n",
        "#    --job-dir gs://your-unique-bucket-name/output \\\n",
        "#    -- \\\n",
        "#    --num-epochs 10\n",
        "\n",
        "# Catatan:\n",
        "# - Ganti 'your-unique-bucket-name' dengan nama bucket GCS Anda.\n",
        "# - 'BASIC_GPU' adalah tier skala yang menyediakan satu worker dengan GPU. Untuk lebih banyak GPU/server, gunakan tier lain seperti 'STANDARD_GPU' atau 'PREMIUM_GPU'.\n",
        "# - Folder 'trainer' dan file 'trainer/task.py' harus ada di direktori lokal Anda dan berisi kode pelatihan TensorFlow.\n",
        "# - Pastikan Anda telah menginstal gcloud SDK dan terautentikasi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvhs0h74thyj"
      },
      "source": [
        "### 6.1 Black Box Hyperparameter Tuning di AI Platform\n",
        "\n",
        "AI Platform menyediakan layanan penyetelan hyperparameter **Bayesian optimization** yang kuat yang disebut **Google Vizier**. Ini dapat mengeksplorasi ruang hyperparameter secara efisien untuk menemukan kombinasi terbaik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "C_VVQNzAthyj"
      },
      "outputs": [],
      "source": [
        "# Contoh file tuning.yaml untuk hyperparameter tuning\n",
        " # trainingInput:\n",
        " #   hyperparameters:\n",
        " #     goal: MAXIMIZE\n",
        " #     hyperparameterMetricTag: accuracy\n",
        " #     maxTrials: 10\n",
        " #     maxParallelTrials: 2\n",
        " #     params:\n",
        " #     - parameterName: learning_rate\n",
        " #       type: DOUBLE\n",
        " #       minValue: 0.001\n",
        " #       maxValue: 0.1\n",
        " #       scaleType: UNIT_LOG_SCALE\n",
        " #     - parameterName: num_neurons\n",
        " #       type: INTEGER\n",
        " #       minValue: 50\n",
        " #       maxValue: 300\n",
        " #       scaleType: UNIT_LINEAR_SCALE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCOSays7thyk"
      },
      "source": [
        "Pekerjaan pelatihan Anda perlu menulis ringkasan (TensorBoard logs) untuk metrik yang ditentukan, yang akan dipantau oleh AI Platform untuk memandu proses penyetelan.\n",
        "\n",
        "## Kesimpulan\n",
        "\n",
        "Bab ini telah membahas berbagai teknik untuk melatih dan menerapkan model TensorFlow dalam skala besar. Kita telah melihat bagaimana TF Serving memungkinkan penerapan model yang efisien dan berskala, serta bagaimana Google Cloud AI Platform menyederhanakan pelatihan dan penerapan di cloud, termasuk penyetelan hyperparameter. Pemahaman tentang strategi distribusi dan pengelolaan GPU sangat penting untuk mengoptimalkan kinerja dalam skala besar."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}