{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxfviuZy_9zY"
      },
      "source": [
        "# Bab 12: Model Kustom dan Pelatihan dengan TensorFlow\n",
        "\n",
        "Bab ini akan menyelam lebih dalam ke dalam API tingkat rendah TensorFlow untuk memungkinkan kustomisasi yang lebih mendalam pada model dan proses pelatihan. Kita akan belajar cara membuat fungsi *loss* kustom, metrik, lapisan, dan bahkan loop pelatihan kustom, serta memanfaatkan fitur *graph* otomatis TensorFlow untuk performa yang lebih baik."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPEatif2_9zd"
      },
      "source": [
        "## 1. Tur Singkat TensorFlow\n",
        "\n",
        "TensorFlow adalah pustaka yang kuat untuk komputasi numerik, dioptimalkan untuk *Machine Learning* skala besar.  Meskipun `tf.keras` adalah API tingkat tinggi yang sering kita gunakan, memahami API tingkat rendahnya memberikan fleksibilitas tambahan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvR5qiRK_9ze"
      },
      "source": [
        "### 1.1. Arsitektur TensorFlow\n",
        "\n",
        "TensorFlow memiliki arsitektur yang dirancang untuk performa dan skalabilitas:\n",
        "* **Inti:** Sangat mirip dengan NumPy, tetapi dengan dukungan GPU.\n",
        "* **Komputasi Terdistribusi:** Mendukung komputasi yang tersebar di banyak perangkat dan *server*.\n",
        "* **Kompiler Just-In-Time (JIT):** Mengoptimalkan komputasi untuk kecepatan dan penggunaan memori dengan mengekstrak *computation graph* dari fungsi Python.\n",
        "* ***Computation Graphs* yang Portabel:** *Graph* dapat diekspor untuk dijalankan di berbagai lingkungan (misalnya, Python di Linux, Java di Android).\n",
        "* ***Autodiff* dan *Optimizers*:** Mengimplementasikan *autodiff* dan menyediakan *optimizer* canggih seperti RMSProp dan Nadam.\n",
        "\n",
        "Pada tingkat terendah, setiap operasi TensorFlow (disebut *op*) diimplementasikan dalam kode C++ yang sangat efisien.  Banyak operasi memiliki implementasi ganda yang disebut *kernel*, masing-masing didedikasikan untuk jenis perangkat tertentu (CPU, GPU, TPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8uxDH3u_9ze"
      },
      "source": [
        "### 1.2. Ekosistem TensorFlow\n",
        "\n",
        "TensorFlow lebih dari sekadar pustaka; ia adalah bagian dari ekosistem yang luas:\n",
        "* **TensorBoard:** Alat visualisasi interaktif untuk kurva pembelajaran, *graph* komputasi, statistik pelatihan, dan lainnya.\n",
        "* **TensorFlow Extended (TFX):** Kumpulan pustaka untuk membuat proyek TensorFlow siap produksi, termasuk validasi data, *preprocessing*, analisis model, dan penyajian.\n",
        "* **TensorFlow Hub:** Untuk mengunduh dan menggunakan kembali jaringan saraf yang sudah dilatih (*pretrained*).\n",
        "* **TensorFlow Model Garden:** Berisi banyak arsitektur jaringan saraf, beberapa di antaranya sudah dilatih.\n",
        "* **TensorFlow Lite:** Untuk menyebarkan model ke perangkat seluler dan *embedded*.\n",
        "* **TensorFlow.js:** Implementasi JavaScript untuk menjalankan model langsung di *browser* web."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI4HDQIJ_9zf"
      },
      "source": [
        "## 2. Menggunakan TensorFlow seperti NumPy\n",
        "\n",
        "API TensorFlow berpusat pada *tensor*, yang mengalir dari satu operasi ke operasi lainnya.  *Tensor* sangat mirip dengan `NumPy ndarray`: biasanya merupakan array multidimensi, tetapi juga dapat menampung *scalar* (nilai tunggal)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFj0xTPw_9zg"
      },
      "source": [
        "### 2.1. Tensor dan Operasi\n",
        "\n",
        "Anda dapat membuat *tensor* dengan `tf.constant()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXWIVWFv_9zh",
        "outputId": "7878c858-32a9-4adf-973d-d8f784d33db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(42, shape=(), dtype=int32)\n",
            "Shape dari t: (2, 3)\n",
            "Dtype dari t: <dtype: 'float32'>\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Membuat tensor matriks\n",
        "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "print(t)\n",
        "\n",
        "# Membuat tensor skalar\n",
        "s = tf.constant(42)\n",
        "print(s)\n",
        "\n",
        "# Mengakses shape dan dtype\n",
        "print(f\"Shape dari t: {t.shape}\")\n",
        "print(f\"Dtype dari t: {t.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZY72wrk_9zj"
      },
      "source": [
        "Pengindeksan (*indexing*) bekerja mirip seperti NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiZsSj_p_9zk",
        "outputId": "b52fa989-dd4d-4cc1-eb95-1d870f5c786f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2. 3.]\n",
            " [5. 6.]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[2.]\n",
            " [5.]], shape=(2, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Pengindeksan baris dan kolom\n",
        "print(t[:, 1:])\n",
        "\n",
        "# Pengindeksan elipsis dan dimensi baru\n",
        "print(t[..., 1, tf.newaxis])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4wjWi0S_9zl"
      },
      "source": [
        "Berbagai operasi *tensor* juga tersedia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBkp_WqM_9zl",
        "outputId": "cb9ef12d-82ff-4259-b470-a8c76b6741fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[11. 12. 13.]\n",
            " [14. 15. 16.]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.  4.  9.]\n",
            " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[14. 32.]\n",
            " [32. 77.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Penjumlahan elemen-demi-elemen\n",
        "print(t + 10)\n",
        "\n",
        "# Pangkat elemen-demi-elemen\n",
        "print(tf.square(t))\n",
        "\n",
        "# Perkalian matriks (dot product)\n",
        "print(t @ tf.transpose(t))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTIgzYhM_9zm"
      },
      "source": [
        "### 2.2. Tensor dan NumPy\n",
        "\n",
        "*Tensor* dan NumPy bekerja sama dengan baik: Anda dapat membuat *tensor* dari array NumPy, dan sebaliknya.  Anda bahkan dapat menerapkan operasi TensorFlow ke array NumPy dan operasi NumPy ke *tensor*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enD8cFp__9zm",
        "outputId": "9f8b074f-da94-422d-d512-afe7937bbf48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2. 4. 5.], shape=(3,), dtype=float64)\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "tf.Tensor([ 4. 16. 25.], shape=(3,), dtype=float64)\n",
            "[[ 1.  4.  9.]\n",
            " [16. 25. 36.]]\n"
          ]
        }
      ],
      "source": [
        "a = np.array([2., 4., 5.])\n",
        "\n",
        "# Membuat tensor dari array NumPy\n",
        "tf_from_np = tf.constant(a)\n",
        "print(tf_from_np)\n",
        "\n",
        "# Mengubah tensor menjadi array NumPy\n",
        "np_from_tf = t.numpy() # atau np.array(t)\n",
        "print(np_from_tf)\n",
        "\n",
        "# Menerapkan operasi TensorFlow pada array NumPy\n",
        "tf_op_on_np = tf.square(a)\n",
        "print(tf_op_on_np)\n",
        "\n",
        "# Menerapkan operasi NumPy pada tensor TensorFlow\n",
        "np_op_on_tf = np.square(t)\n",
        "print(np_op_on_tf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAxJg46Q_9zn"
      },
      "source": [
        "**Catatan Penting:** NumPy menggunakan presisi 64-bit secara *default*, sedangkan TensorFlow menggunakan 32-bit. Disarankan untuk mengatur `dtype=tf.float32` saat membuat *tensor* dari array NumPy untuk konsistensi dan performa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcYKQWMW_9zn"
      },
      "source": [
        "### 2.3. Konversi Tipe\n",
        "\n",
        "TensorFlow tidak melakukan konversi tipe secara otomatis untuk menghindari dampak performa yang signifikan dan tidak disadari.  Ini akan memunculkan *exception* jika Anda mencoba melakukan operasi pada *tensor* dengan tipe yang tidak kompatibel.  Anda dapat menggunakan `tf.cast()` jika perlu mengonversi tipe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03q1xEPR_9zn",
        "outputId": "4fc6b3f8-3d51-4920-99e3-87c7a2ffd678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(42.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Contoh error karena tipe tidak kompatibel (akan memunculkan error jika dijalankan)\n",
        "# tf.constant(2.) + tf.constant(40)\n",
        "\n",
        "# Contoh konversi tipe\n",
        "t2 = tf.constant(40., dtype=tf.float64)\n",
        "converted_sum = tf.constant(2.0) + tf.cast(t2, tf.float32)\n",
        "print(converted_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDorBWtm_9zn"
      },
      "source": [
        "### 2.4. Variabel\n",
        "\n",
        "Nilai `tf.Tensor` yang telah kita lihat sejauh ini bersifat *immutable* (tidak dapat diubah).  Ini berarti kita tidak bisa menggunakan *tensor* biasa untuk mengimplementasikan bobot dalam jaringan saraf, karena bobot perlu disesuaikan oleh *backpropagation*.  Untuk itu, kita memerlukan `tf.Variable`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cee2zXL_9zn",
        "outputId": "dadba736-b6d5-4c4d-89ff-a9dd0efbee15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "       [4., 5., 6.]], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 2.,  4.,  6.],\n",
            "       [ 8., 10., 12.]], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 2., 42.,  6.],\n",
            "       [ 8., 10., 12.]], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 2., 42.,  0.],\n",
            "       [ 8., 10.,  1.]], dtype=float32)>\n"
          ]
        }
      ],
      "source": [
        "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
        "print(v)\n",
        "\n",
        "# Modifikasi nilai variabel di tempat (in-place)\n",
        "v.assign(2 * v)\n",
        "print(v)\n",
        "\n",
        "v[0, 1].assign(42)\n",
        "print(v)\n",
        "\n",
        "v[:, 2].assign([0., 1.])\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJnLkJzk_9zo"
      },
      "source": [
        "Meskipun `tf.Variable` bertindak mirip dengan `tf.Tensor`, dan mendukung operasi yang sama, ia juga dapat dimodifikasi di tempat menggunakan metode `assign()` (atau `assign_add()` atau `assign_sub()`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-dGny0g_9zo"
      },
      "source": [
        "### 2.5. Struktur Data Lainnya\n",
        "\n",
        "TensorFlow mendukung beberapa struktur data lainnya:\n",
        "* ***Sparse tensors* (`tf.SparseTensor`):** Merepresentasikan *tensor* yang sebagian besar berisi nol secara efisien.\n",
        "* ***Tensor arrays* (`tf.TensorArray`):** Daftar *tensor*. Ukurannya tetap secara *default* tetapi dapat dibuat dinamis.\n",
        "* ***Ragged tensors* (`tf.RaggedTensor`):** Merepresentasikan daftar statis dari daftar *tensor* di mana setiap *tensor* memiliki *shape* dan tipe data yang sama, tetapi panjang *slice*nya bisa berbeda.\n",
        "* ***String tensors*:** *Tensor* biasa dengan `dtype=tf.string`. Merepresentasikan *byte strings* (bukan *Unicode strings*).\n",
        "* **Sets:** Merepresentasikan *set* sebagai *tensor* biasa (atau *sparse tensor*).\n",
        "* **Queues:** Menyimpan *tensor* di banyak *step*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv_7DOP5_9zo"
      },
      "source": [
        "## 3. Mengkustomisasi Model dan Algoritma Pelatihan\n",
        "\n",
        "Bagian ini membahas cara mengimplementasikan komponen kustom untuk model TensorFlow Anda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rdb6OVl_9zo"
      },
      "source": [
        "### 3.1. Fungsi *Loss* Kustom\n",
        "\n",
        "Misalnya Anda ingin melatih model regresi, tetapi *training set* Anda sedikit *noisy*.  Fungsi *loss* *mean squared error* (MSE) mungkin terlalu banyak menghukum *error* besar.  *Mean absolute error* (MAE) tidak terlalu sensitif terhadap *outlier*, tetapi pelatihan bisa lambat.  *Huber loss* (diperkenalkan dalam Bab 10) adalah alternatif yang baik.\n",
        "\n",
        "Anda dapat membuat fungsi *loss* kustom dengan membuat fungsi Python yang mengambil *label* (`y_true`) dan prediksi (`y_pred`) sebagai argumen, dan mengembalikan *tensor* yang berisi satu *loss* per *instance*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QucXbGxg_9zo",
        "outputId": "4f359784-5bd1-46a9-d3f6-1baefb9f582e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - loss: 0.0848 - val_loss: 0.0682\n",
            "Epoch 2/2\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0804 - val_loss: 0.0621\n"
          ]
        }
      ],
      "source": [
        "# Contoh data fiktif\n",
        "X_train_scaled = np.random.rand(100, 10).astype(np.float32)\n",
        "y_train = np.random.rand(100, 1).astype(np.float32)\n",
        "X_valid = np.random.rand(20, 10).astype(np.float32)\n",
        "y_valid = np.random.rand(20, 1).astype(np.float32)\n",
        "\n",
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = tf.abs(error) - 0.5\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\", input_shape=[10]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afalQpJt_9zo"
      },
      "source": [
        "Untuk performa yang lebih baik, gunakan implementasi *vectorized* dan hanya operasi TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vepH6XKq_9zp"
      },
      "source": [
        "### 3.2. Menyimpan dan Memuat Model yang Mengandung Komponen Kustom\n",
        "\n",
        "Saat menyimpan model yang berisi fungsi *loss* kustom, Keras menyimpan nama fungsi tersebut.  Saat memuatnya, Anda perlu menyediakan *dictionary* yang memetakan nama fungsi ke fungsi yang sebenarnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "el6171Qh_9zp"
      },
      "outputs": [],
      "source": [
        "# Asumsikan model sudah dilatih dan disimpan sebelumnya\n",
        "# model.save(\"my_model_with_a_custom_loss.h5\")\n",
        "\n",
        "# Memuat model dengan fungsi loss kustom\n",
        "# model = tf.keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
        "#                                    custom_objects={\"huber_fn\": huber_fn})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkXDFdwT_9zp"
      },
      "source": [
        "Jika fungsi *loss* kustom Anda memiliki *hyperparameter* yang perlu disimpan, Anda bisa membuat *subclass* dari `tf.keras.losses.Loss` dan mengimplementasikan metode `get_config()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4PMq0h__9zp",
        "outputId": "3fe07efe-bc31-4ab9-ce9a-610894cef8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0744 - val_loss: 0.0565\n",
            "Epoch 2/2\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0682 - val_loss: 0.0543\n"
          ]
        }
      ],
      "source": [
        "class HuberLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}\n",
        "\n",
        "model.compile(loss=HuberLoss(2.0), optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# Menyimpan model dengan class custom loss\n",
        "# model.save(\"my_model_with_a_custom_loss_class.h5\")\n",
        "\n",
        "# Memuat model dengan class custom loss\n",
        "# model = tf.keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
        "#                                    custom_objects={\"HuberLoss\": HuberLoss})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW0zF-Uw_9zr"
      },
      "source": [
        "### 3.3. Fungsi Aktivasi Kustom, Inisialisasi, Regularizer, dan Batasan\n",
        "\n",
        "Sebagian besar fungsionalitas Keras (misalnya, *losses*, *regularizers*, *constraints*, *initializers*, *metrics*, fungsi aktivasi, *layers*, dan bahkan model lengkap) dapat dikustomisasi dengan cara yang sama.  Seringkali, Anda hanya perlu menulis fungsi sederhana dengan *input* dan *output* yang sesuai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PNdkdiZj_9zr"
      },
      "outputs": [],
      "source": [
        "def my_softplus(z): # Contoh fungsi aktivasi kustom\n",
        "    return tf.math.log(tf.exp(z) + 1.0)\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32): # Contoh inisialisasi kustom\n",
        "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "def my_l1_regularizer(weights): # Contoh regularizer kustom\n",
        "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "def my_positive_weights(weights): # Contoh batasan (constraint) kustom\n",
        "    return tf.where(weights < 0., tf.zeros_like(weights), weights)\n",
        "\n",
        "layer_custom = tf.keras.layers.Dense(30, activation=my_softplus,\n",
        "                                     kernel_initializer=my_glorot_initializer,\n",
        "                                     kernel_regularizer=my_l1_regularizer,\n",
        "                                     kernel_constraint=my_positive_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv62IgvB_9zs"
      },
      "source": [
        "### 3.4. Metrik Kustom\n",
        "\n",
        "*Loss* dan metrik secara konseptual berbeda: *loss* digunakan oleh *Gradient Descent* untuk melatih model dan harus *differentiable*, sementara metrik digunakan untuk mengevaluasi model dan harus mudah diinterpretasikan.\n",
        "\n",
        "Metrik *streaming* (atau *stateful*) adalah metrik yang diperbarui secara bertahap, *batch* demi *batch*.  Anda dapat membuat *subclass* dari `tf.keras.metrics.Metric` untuk metrik *streaming*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBwM_0u1_9zs",
        "outputId": "753a1776-a8b2-43cf-a7f2-8f1ced098eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - huber_metric_1: 0.2565 - loss: 0.5255 - val_huber_metric_1: 0.3239 - val_loss: 0.6791\n",
            "Epoch 2/2\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_metric_1: 0.2315 - loss: 0.4715 - val_huber_metric_1: 0.2955 - val_loss: 0.6157\n"
          ]
        }
      ],
      "source": [
        "# Contoh data fiktif (seperti di notebook Anda)\n",
        "X_train_scaled = np.random.rand(100, 10).astype(np.float32)\n",
        "y_train = np.random.rand(100, 1).astype(np.float32)\n",
        "X_valid = np.random.rand(20, 10).astype(np.float32)\n",
        "y_valid = np.random.rand(20, 1).astype(np.float32)\n",
        "\n",
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = tf.abs(error) - 0.5\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "class HuberMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = huber_fn # Menggunakan fungsi huber_fn yang sudah didefinisikan\n",
        "        # PERBAIKAN DI SINI: tambahkan argumen shape=() untuk variabel skalar\n",
        "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\", shape=())\n",
        "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\", shape=())\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        metric = self.huber_fn(y_true, y_pred)\n",
        "        self.total.assign_add(tf.reduce_sum(metric))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}\n",
        "\n",
        "# Uji model dengan metrik yang diperbaiki\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\", input_shape=[10]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[HuberMetric(2.0)])\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwVHubhT_9zs"
      },
      "source": [
        "### 3.5. Lapisan Kustom\n",
        "\n",
        "Jika Anda ingin membangun arsitektur yang berisi lapisan *exotic* yang tidak disediakan oleh TensorFlow, atau jika Anda ingin memperlakukan blok lapisan berulang sebagai satu lapisan, Anda dapat membuat lapisan kustom.\n",
        "\n",
        "Untuk lapisan tanpa bobot, gunakan `tf.keras.layers.Lambda`.  Untuk lapisan *stateful* (dengan bobot), buat *subclass* dari `tf.keras.layers.Layer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhM11YdM_9zs",
        "outputId": "4e7d2624-aaa5-4ef5-cb7b-a24b675be7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.2084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78cf5887a490>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Contoh data fiktif (seperti di notebook Anda)\n",
        "X_train_scaled = np.random.rand(100, 10).astype(np.float32)\n",
        "y_train = np.random.rand(100, 1).astype(np.float32)\n",
        "X_valid = np.random.rand(20, 10).astype(np.float32)\n",
        "y_valid = np.random.rand(20, 1).astype(np.float32)\n",
        "\n",
        "def my_softplus(z): # Contoh fungsi aktivasi kustom\n",
        "    return tf.math.log(tf.exp(z) + 1.0)\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32): # Contoh inisialisasi kustom\n",
        "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "def my_l1_regularizer(weights): # Contoh regularizer kustom\n",
        "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "def my_positive_weights(weights): # Contoh batasan (constraint) kustom\n",
        "    return tf.where(weights < 0., tf.zeros_like(weights), weights)\n",
        "\n",
        "class MyDense(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
        "            initializer=\"glorot_normal\")\n",
        "        self.bias = self.add_weight(\n",
        "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
        "        super().build(batch_input_shape) # Harus di akhir\n",
        "\n",
        "    def call(self, X):\n",
        "        return self.activation(tf.matmul(X, self.kernel) + self.bias)\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        # PERBAIKAN DI SINI: Akses elemen shape secara langsung atau konversi ke list yang benar\n",
        "        # Cara paling robust adalah dengan mengubahnya menjadi list terlebih dahulu\n",
        "        input_shape_list = list(batch_input_shape) # Mengkonversi tf.TensorShape menjadi list\n",
        "        return tf.TensorShape(input_shape_list[:-1] + [self.units])\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"units\": self.units,\n",
        "                \"activation\": tf.keras.activations.serialize(self.activation)}\n",
        "\n",
        "# Menggunakan lapisan kustom\n",
        "model_custom_layer = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=[10]),\n",
        "    MyDense(5, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model_custom_layer.compile(loss=\"mse\", optimizer=\"sgd\")\n",
        "model_custom_layer.fit(X_train_scaled, y_train, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q2NjcpH_9zt"
      },
      "source": [
        "Jika lapisan Anda perlu memiliki perilaku yang berbeda selama pelatihan dan pengujian (misalnya, jika menggunakan `Dropout` atau `BatchNormalization`), Anda harus menambahkan argumen `training` ke metode `call()` dan menggunakannya untuk memutuskan apa yang harus dihitung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoSjeHJ-_9zt"
      },
      "source": [
        "### 3.6. Model Kustom\n",
        "\n",
        "Seperti yang telah kita lihat di Bab 10, membuat kelas model kustom sangat mudah: cukup buat *subclass* dari kelas `tf.keras.Model`, buat *layer* dan *variabel* di *constructor*, dan implementasikan metode `call()` untuk melakukan apa pun yang Anda inginkan model lakukan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_58wMKv_9zt",
        "outputId": "87e897c6-24f2-4d27-e4d4-2630558373c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: nan    \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78cf58716710>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "class ResidualBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [tf.keras.layers.Dense(n_neurons, activation=\"elu\",\n",
        "                                            kernel_initializer=\"he_normal\")\n",
        "                       for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        return inputs + Z # Skip connection\n",
        "\n",
        "class ResidualRegressor(tf.keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = tf.keras.layers.Dense(30, activation=\"elu\",\n",
        "                                            kernel_initializer=\"he_normal\")\n",
        "        self.block1 = ResidualBlock(2, 30)\n",
        "        self.block2 = ResidualBlock(2, 30)\n",
        "        self.out = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = self.hidden1(inputs)\n",
        "        for _ in range(1 + 3): # Asumsi loop contoh dari buku\n",
        "            Z = self.block1(Z)\n",
        "        Z = self.block2(Z)\n",
        "        return self.out(Z)\n",
        "\n",
        "model_custom_residual = ResidualRegressor(output_dim=1)\n",
        "model_custom_residual.compile(loss=\"mse\", optimizer=\"sgd\")\n",
        "model_custom_residual.fit(X_train_scaled, y_train, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71uZPkzC_9zu"
      },
      "source": [
        "Kelas `Model` adalah *subclass* dari kelas `Layer`, jadi model dapat didefinisikan dan digunakan persis seperti *layer*.  Namun, sebuah model memiliki fungsionalitas tambahan, seperti metode `compile()`, `fit()`, `evaluate()`, dan `predict()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLlfhGtG_9zu"
      },
      "source": [
        "### 3.7. *Loss* dan Metrik Berbasis Internal Model\n",
        "\n",
        "Anda bisa mendefinisikan *loss* atau metrik berdasarkan bagian lain dari model Anda, seperti bobot atau aktivasi lapisan tersembunyi.  Ini bisa berguna untuk tujuan *regularization* atau untuk memantau aspek internal model.\n",
        "\n",
        "Untuk mendefinisikan *loss* kustom berdasarkan internal model, hitung *loss* tersebut berdasarkan bagian model yang Anda inginkan, lalu berikan hasilnya ke metode `add_loss()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C70Bb3ml_9zz",
        "outputId": "d3048489-1ca9-4b55-f81e-8f854cda3ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.6315\n",
            "Epoch 2/2\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1580 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78cf59005790>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "class ReconstructingRegressor(tf.keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [tf.keras.layers.Dense(30, activation=\"selu\",\n",
        "                                            kernel_initializer=\"lecun_normal\")\n",
        "                       for _ in range(5)]\n",
        "        self.out = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        n_inputs = batch_input_shape[-1]\n",
        "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        reconstruction = self.reconstruct(Z)\n",
        "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
        "        self.add_loss(0.05 * recon_loss) # Menambahkan loss kustom\n",
        "        return self.out(Z)\n",
        "\n",
        "model_reconstructing = ReconstructingRegressor(output_dim=1)\n",
        "model_reconstructing.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
        "model_reconstructing.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPSeU9kr_9zz"
      },
      "source": [
        "### 3.8. Menghitung Gradien Menggunakan *Autodiff*\n",
        "\n",
        "TensorFlow memungkinkan Anda menghitung gradien secara otomatis menggunakan *autodiff*.  Anda dapat menggunakan konteks `tf.GradientTape()` untuk merekam operasi yang melibatkan *variabel*, lalu meminta *tape* untuk menghitung gradien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUjnHH0R_9z0",
        "outputId": "b1c5169e-c366-4019-9b77-1b1c5f3f89c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n"
          ]
        }
      ],
      "source": [
        "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
        "\n",
        "def f(w1, w2):\n",
        "    return 3 * w1**2 + 2 * w1 * w2\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "gradients = tape.gradient(z, [w1, w2])\n",
        "print(gradients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLKfsbw2_9z0"
      },
      "source": [
        "*Tape* secara otomatis dihapus setelah Anda memanggil metode `gradient()`.  Jika Anda perlu memanggilnya lebih dari sekali, Anda harus membuat *tape* menjadi *persistent*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBO5JMhc_9z0",
        "outputId": "0450f0de-4ac2-45cc-f3c1-b2bc2644ffb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(36.0, shape=(), dtype=float32)\n",
            "tf.Tensor(10.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "dz_dw1 = tape.gradient(z, w1)\n",
        "dz_dw2 = tape.gradient(z, w2)\n",
        "print(dz_dw1)\n",
        "print(dz_dw2)\n",
        "del tape # Penting untuk menghapus tape persistent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GROop5Xy_9z0"
      },
      "source": [
        "### 3.9. Loop Pelatihan Kustom\n",
        "\n",
        "Dalam kasus yang jarang terjadi, metode `fit()` mungkin tidak cukup fleksibel untuk kebutuhan Anda.  Misalnya, jika Anda perlu menggunakan *optimizer* yang berbeda untuk bagian yang berbeda dari jaringan saraf Anda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKS2sY08_9z0",
        "outputId": "fd6f10b1-49ca-4621-e7f8-c5518bc5dc1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " - val_loss: 0.2183\n",
            "Epoch 2/5\n",
            " - val_loss: 0.2116\n",
            "Epoch 3/5\n",
            " - val_loss: 0.1838\n",
            "Epoch 4/5\n",
            " - val_loss: 0.1792\n",
            "Epoch 5/5\n",
            " - val_loss: 0.1245\n"
          ]
        }
      ],
      "source": [
        "# Contoh sederhana loop pelatihan kustom (tanpa validasi atau metrik penuh)\n",
        "# Untuk contoh lengkap, lihat buku atau notebook GitHub\n",
        "\n",
        "l2_reg = tf.keras.regularizers.l2(0.05)\n",
        "model_custom_loop = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
        "                         kernel_regularizer=l2_reg),\n",
        "    tf.keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.mse\n",
        "\n",
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps_per_epoch = len(X_train_scaled) // batch_size\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
        "    for step in range(n_steps_per_epoch):\n",
        "        # Ambil batch acak (sederhana, untuk contoh)\n",
        "        idx = np.random.randint(len(X_train_scaled), size=batch_size)\n",
        "        X_batch, y_batch = X_train_scaled[idx], y_train[idx]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model_custom_loop(X_batch, training=True)\n",
        "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "            loss = tf.add_n([main_loss] + model_custom_loop.losses) # Tambahkan losses regularisasi\n",
        "\n",
        "        gradients = tape.gradient(loss, model_custom_loop.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model_custom_loop.trainable_variables))\n",
        "\n",
        "    # Evaliasi sederhana di akhir epoch\n",
        "    val_loss = tf.reduce_mean(loss_fn(y_valid, model_custom_loop(X_valid)))\n",
        "    print(f\" - val_loss: {val_loss.numpy():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu_KXVLM_9z1"
      },
      "source": [
        "Menulis *loop* pelatihan kustom memberi Anda kendali penuh, tetapi juga membuat kode lebih panjang dan lebih rentan terhadap *error*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xxzJgR6_9z1"
      },
      "source": [
        "## 4. Fungsi dan *Graph* TensorFlow\n",
        "\n",
        "TensorFlow dapat mengoptimalkan fungsi Python dengan mengubahnya menjadi *TensorFlow Functions* (*TF Functions*).  Ini biasanya mempercepat eksekusi, terutama untuk komputasi yang kompleks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StufM9KQ_9z1"
      },
      "source": [
        "### 4.1. Fungsi dan *Concrete Functions*\n",
        "\n",
        "*TF Functions* bersifat *polymorphic*, artinya mereka mendukung *input* dengan tipe dan *shape* yang berbeda.  Setiap kali Anda memanggil *TF Function* dengan kombinasi *input* baru, ia menghasilkan *concrete function* baru dengan *graph* sendiri yang khusus untuk kombinasi tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dP_sOhi_9z2",
        "outputId": "c0103e9b-47f1-43e1-bec1-6f1f5c2efa8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = 2\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "x = 3\n",
            "tf.Tensor(27, shape=(), dtype=int32)\n",
            "x = Tensor(\"x:0\", shape=(), dtype=float32)\n",
            "tf.Tensor(8.0, shape=(), dtype=float32)\n",
            "x = Tensor(\"x:0\", shape=(1,), dtype=float32)\n",
            "tf.Tensor([8.], shape=(1,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "@tf.function\n",
        "def tf_cube(x):\n",
        "    print(f\"x = {x}\") # Ini hanya akan dieksekusi saat fungsi dilacak (traced)\n",
        "    return x ** 3\n",
        "\n",
        "# Panggilan pertama: melacak fungsi untuk int32 skalar\n",
        "result_int = tf_cube(2)\n",
        "print(result_int)\n",
        "\n",
        "# Panggilan kedua: menggunakan fungsi yang dilacak\n",
        "result_int_again = tf_cube(3)\n",
        "print(result_int_again)\n",
        "\n",
        "# Panggilan ketiga: melacak fungsi untuk float32 skalar\n",
        "result_float = tf_cube(tf.constant(2.0))\n",
        "print(result_float)\n",
        "\n",
        "# Panggilan keempat: melacak fungsi untuk float32 tensor shape (1,)\n",
        "result_tensor_1d = tf_cube(tf.constant([2.0]))\n",
        "print(result_tensor_1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcvK2DD-_9z2"
      },
      "source": [
        "Anda dapat melihat *graph* komputasi dari *concrete function* menggunakan atribut `.graph`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yqaEZzT_9z2"
      },
      "source": [
        "### 4.2. *AutoGraph* dan *Tracing*\n",
        "\n",
        "TensorFlow menghasilkan *graph* melalui *AutoGraph* dan *tracing*. *AutoGraph* menganalisis kode sumber Python untuk menangkap semua pernyataan alur kontrol (seperti *loop* `for`, `while`, `if`).  Kemudian TensorFlow memanggil fungsi yang telah \"ditingkatkan\" ini dengan *symbolic tensor* (tanpa nilai sebenarnya, hanya nama, tipe data, dan *shape*).\n",
        "\n",
        "*Loop* `for` yang berulang pada `tf.range()` akan diubah menjadi *dynamic loop* dalam *graph* komputasi, sedangkan *loop* `for` yang berulang pada `range()` Python biasa akan menjadi *static loop* dan \"dilepaskan\" selama *tracing*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUF0XmT8_9z2",
        "outputId": "bef3bf03-cfaa-4a2a-ee03-dea51fb441e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Operation 'x' type=Placeholder>, <tf.Operation 'add/y' type=Const>, <tf.Operation 'add' type=AddV2>, <tf.Operation 'add_1/y' type=Const>, <tf.Operation 'add_1' type=AddV2>, <tf.Operation 'add_2/y' type=Const>, <tf.Operation 'add_2' type=AddV2>, <tf.Operation 'add_3/y' type=Const>, <tf.Operation 'add_3' type=AddV2>, <tf.Operation 'add_4/y' type=Const>, <tf.Operation 'add_4' type=AddV2>, <tf.Operation 'add_5/y' type=Const>, <tf.Operation 'add_5' type=AddV2>, <tf.Operation 'add_6/y' type=Const>, <tf.Operation 'add_6' type=AddV2>, <tf.Operation 'add_7/y' type=Const>, <tf.Operation 'add_7' type=AddV2>, <tf.Operation 'add_8/y' type=Const>, <tf.Operation 'add_8' type=AddV2>, <tf.Operation 'add_9/y' type=Const>, <tf.Operation 'add_9' type=AddV2>, <tf.Operation 'Identity' type=Identity>]\n"
          ]
        }
      ],
      "source": [
        "@tf.function\n",
        "def add_10_dynamic(x):\n",
        "    for i in tf.range(10): # Menggunakan tf.range untuk loop dinamis\n",
        "        x += 1\n",
        "    return x\n",
        "\n",
        "# Melihat operasi graph untuk loop dinamis\n",
        "# print(add_10_dynamic.get_concrete_function(tf.constant(0)).graph.get_operations())\n",
        "\n",
        "@tf.function\n",
        "def add_10_static(x):\n",
        "    for i in range(10): # Menggunakan range() untuk loop statis\n",
        "        x += 1\n",
        "    return x\n",
        "\n",
        "# Melihat operasi graph untuk loop statis (akan ada 10 operasi 'add')\n",
        "print(add_10_static.get_concrete_function(tf.constant(0)).graph.get_operations())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb5Pj4Rc_9z2"
      },
      "source": [
        "### 4.3. Aturan Fungsi TF\n",
        "\n",
        "Ada beberapa aturan yang perlu diperhatikan saat menulis *TF Functions*:\n",
        "* Gunakan operasi TensorFlow, bukan pustaka eksternal (NumPy, dll.), karena panggilan ini hanya berjalan selama *tracing*.\n",
        "* Hindari efek samping non-TensorFlow yang tidak terduga, karena efek samping ini hanya terjadi selama *tracing*.\n",
        "* Buat *variabel* TensorFlow di luar *TF Function* atau pada panggilan pertama, dan gunakan metode `assign()` untuk memodifikasinya (bukan operator `=`, `+=`, dll.).\n",
        "* Kode sumber fungsi Python Anda harus tersedia untuk TensorFlow.\n",
        "* Gunakan `tf.range()` untuk *loop* yang ingin Anda sertakan dalam *graph* komputasi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbLsU0Hb_9z3"
      },
      "source": [
        "## Kesimpulan\n",
        "\n",
        "Bab ini telah memberikan pemahaman yang mendalam tentang cara mengkustomisasi model dan alur pelatihan di TensorFlow, mulai dari tingkat API rendah hingga penggunaan *TF Functions* untuk optimasi. Dengan pengetahuan ini, Anda dapat membangun arsitektur jaringan saraf yang lebih kompleks dan menyesuaikan proses pelatihan untuk memenuhi kebutuhan spesifik proyek *Machine Learning* Anda."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}