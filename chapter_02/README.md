### **Ringkasan Bab 2: Proyek Machine Learning End-to-End**

Bab 2 dari buku "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow" (Edisi ke-2) oleh Aurélien Géron menyajikan panduan praktis dan komprehensif tentang langkah-langkah dalam proyek Machine Learning (ML) yang realistis. [cite_start]Bab ini memposisikan pembaca sebagai seorang *data scientist* yang baru direkrut di perusahaan real estat, dengan tugas memprediksi harga perumahan di California berdasarkan data sensus.

[cite_start]Bab ini secara sistematis memandu pembaca melalui delapan langkah utama dalam alur kerja proyek ML:

1.  [cite_start]**Melihat Gambaran Besar (Look at the Big Picture)**: Tahap ini menekankan pentingnya memahami tujuan bisnis di balik proyek ML. [cite_start]Pembaca diajak untuk membingkai masalah (apakah ini masalah *supervised/unsupervised learning*, *classification/regression*, atau *batch/online learning*)  [cite_start]dan memilih metrik kinerja yang sesuai (misalnya, *Root Mean Square Error* untuk regresi). [cite_start]Selain itu, penting untuk memeriksa asumsi-asumsi awal agar tidak terjadi kesalahan fatal di kemudian hari.

2.  [cite_start]**Mendapatkan Data (Get the Data)**: Langkah ini mencakup proses pengumpulan data yang relevan. [cite_start]Penulis menyarankan untuk membuat ruang kerja yang terisolasi (misalnya dengan `virtualenv`)  [cite_start]dan mengotomatiskan proses pengunduhan data untuk mempermudah reproduksi dan pembaruan data di masa mendatang. [cite_start]Setelah data diunduh, dilakukan pemeriksaan cepat terhadap struktur data menggunakan metode pandas seperti `head()`, `info()`, `describe()`, dan `hist()` untuk memahami tipe dan distribusi atribut. [cite_start]**Poin krusial** pada tahap ini adalah membuat *test set* dan menyisihkannya segera untuk menghindari *data snooping bias* yang dapat menghasilkan evaluasi model yang terlalu optimis. [cite_start]Teknik *stratified sampling* diperkenalkan untuk memastikan *test set* merepresentasikan distribusi data secara keseluruhan.

3.  [cite_start]**Menjelajahi dan Memvisualisasikan Data untuk Mendapatkan Wawasan (Discover and Visualize the Data to Gain Insights)**: Pada tahap ini, pembaca didorong untuk menganalisis *training set* secara mendalam (tanpa menyentuh *test set*). [cite_start]Visualisasi data geografis menggunakan *scatter plot* sangat membantu untuk melihat pola spasial. [cite_start]Menghitung koefisien korelasi antar atribut  [cite_start]dan memvisualisasikannya dengan `scatter_matrix()` membantu mengidentifikasi hubungan penting dalam data. [cite_start]Eksperimen dengan kombinasi atribut baru (misalnya, `rooms_per_household`) juga dapat mengungkapkan fitur yang lebih informatif.

4.  [cite_start]**Mempersiapkan Data untuk Algoritma Machine Learning (Prepare the Data for Machine Learning Algorithms)**: Ini adalah salah satu tahap terpenting dan seringkali paling memakan waktu[cite: 92, 109]. [cite_start]Penulis menekankan untuk menulis fungsi-fungsi transformasi data agar prosesnya dapat direproduksi dan digunakan kembali[cite: 92, 109]. [cite_start]Tahap ini meliputi pembersihan data (menangani nilai yang hilang, misalnya dengan `SimpleImputer`) [cite: 93, 110][cite_start], mengubah atribut teks dan kategorikal menjadi format numerik (misalnya dengan *one-hot encoding* menggunakan `OneHotEncoder`) [cite: 96, 97, 113, 114][cite_start], membuat *custom transformer* untuk transformasi spesifik [cite: 98, 115][cite_start], dan melakukan *feature scaling* (misalnya *standardization* dengan `StandardScaler`) untuk memastikan atribut memiliki skala yang serupa. [cite_start]Konsep *pipeline transformasi* menggunakan `Pipeline` dan `ColumnTransformer` dari Scikit-Learn diperkenalkan untuk mengurutkan dan mengotomatiskan langkah-langkah ini secara efisien.

5.  **Memilih dan Melatih Model (Select and Train a Model)**: Setelah data siap, berbagai model ML mulai dicoba. [cite_start]Bab ini mendemonstrasikan pelatihan dan evaluasi model *Linear Regression* dan *DecisionTreeRegressor* pada *training set*. [cite_start]Perbandingan performa awal menunjukkan potensi *underfitting* (pada *Linear Regression*) dan *overfitting* (pada *DecisionTreeRegressor*). [cite_start]Untuk evaluasi yang lebih handal dan mendeteksi *overfitting* secara akurat, teknik *K-fold cross-validation* diperkenalkan menggunakan `cross_val_score()`.

6.  **Menyesuaikan Model Anda (Fine-Tune Your Model)**: Setelah model-model awal diidentifikasi, fokus bergeser pada penyempurnaan *hyperparameter*. [cite_start]Metode *Grid Search* (`GridSearchCV`)  [cite_start]dan *Randomized Search* (`RandomizedSearchCV`)  dijelaskan sebagai cara otomatis untuk mengeksplorasi ruang *hyperparameter* dan menemukan kombinasi terbaik melalui *cross-validation*. [cite_start]Konsep *Ensemble Methods* (seperti *Random Forests*) juga ditekankan sebagai cara untuk meningkatkan kinerja model secara keseluruhan. [cite_start]Menganalisis model terbaik dan kesalahannya (misalnya, dengan melihat *feature importances* dari *Random Forests*) memberikan wawasan tambahan untuk perbaikan.

7.  [cite_start]**Mengevaluasi Sistem pada Test Set (Evaluate Your System on the Test Set)**: Setelah model disempurnakan dan diverifikasi pada *validation set*, langkah terakhir adalah mengevaluasinya pada *test set* yang benar-benar baru. [cite_start]Ini memberikan estimasi *generalization error* yang tidak bias sebelum model diluncurkan ke produksi. [cite_start]Penting untuk **tidak melakukan penyesuaian** pada model setelah evaluasi *test set* ini untuk menjaga integritas estimasi.

8.  [cite_start]**Meluncurkan, Memantau, dan Memelihara Sistem Anda (Launch, Monitor, and Maintain Your System)**: Tahap akhir ini membahas persiapan model untuk deployment (misalnya, menyimpan model dengan `joblib`  [cite_start]atau format SavedModel TensorFlow untuk *serving* ). [cite_start]Aspek penting lainnya adalah *monitoring* kinerja model di lingkungan produksi (misalnya, mendeteksi *model rot* karena perubahan data seiring waktu)  [cite_start]dan mengotomatiskan proses pelatihan ulang model secara berkala dengan data yang segar. [cite_start]Memiliki sistem *backup* dan *rollback* juga krusial untuk menghadapi potensi masalah.

Secara keseluruhan, Bab 2 berfungsi sebagai "laboratorium" mini yang membekali pembaca dengan pemahaman praktis dan keterampilan esensial untuk menjalani siklus hidup proyek Machine Learning secara lengkap, menekankan pentingnya setiap tahapan dan alat-alat praktis yang tersedia di Scikit-Learn.
